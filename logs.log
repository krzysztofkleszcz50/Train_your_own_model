2024-11-25 19:57:40,530:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-25 19:57:40,531:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-25 19:57:40,531:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-25 19:57:40,531:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-25 19:59:07,280:INFO:PyCaret ClassificationExperiment
2024-11-25 19:59:07,281:INFO:Logging name: clf-default-name
2024-11-25 19:59:07,282:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-25 19:59:07,284:INFO:version 3.3.1
2024-11-25 19:59:07,285:INFO:Initializing setup()
2024-11-25 19:59:07,287:INFO:self.USI: b2b7
2024-11-25 19:59:07,341:INFO:self._variable_keys: {'idx', 'exp_name_log', '_available_plots', 'USI', 'target_param', 'fold_generator', 'X_train', 'fold_shuffle_param', '_ml_usecase', 'is_multiclass', 'gpu_n_jobs_param', 'fold_groups_param', 'logging_param', 'seed', 'exp_id', 'X_test', 'pipeline', 'data', 'n_jobs_param', 'fix_imbalance', 'html_param', 'X', 'y_test', 'memory', 'y_train', 'log_plots_param', 'gpu_param', 'y'}
2024-11-25 19:59:07,341:INFO:Checking environment
2024-11-25 19:59:07,341:INFO:python_version: 3.11.9
2024-11-25 19:59:07,341:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-11-25 19:59:07,341:INFO:machine: AMD64
2024-11-25 19:59:07,440:INFO:platform: Windows-10-10.0.19045-SP0
2024-11-25 19:59:07,440:INFO:Memory: svmem(total=17107767296, available=8220626944, percent=51.9, used=8887140352, free=8220626944)
2024-11-25 19:59:07,440:INFO:Physical Core: 4
2024-11-25 19:59:07,440:INFO:Logical Core: 4
2024-11-25 19:59:07,440:INFO:Checking libraries
2024-11-25 19:59:07,440:INFO:System:
2024-11-25 19:59:07,440:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-11-25 19:59:07,440:INFO:executable: C:\Users\krzys\.conda\envs\datascience\python.exe
2024-11-25 19:59:07,440:INFO:   machine: Windows-10-10.0.19045-SP0
2024-11-25 19:59:07,440:INFO:PyCaret required dependencies:
2024-11-25 19:59:07,530:INFO:                 pip: 24.0
2024-11-25 19:59:07,531:INFO:          setuptools: 69.5.1
2024-11-25 19:59:07,531:INFO:             pycaret: 3.3.2
2024-11-25 19:59:07,531:INFO:             IPython: 8.25.0
2024-11-25 19:59:07,531:INFO:          ipywidgets: 7.8.1
2024-11-25 19:59:07,531:INFO:                tqdm: 4.66.5
2024-11-25 19:59:07,531:INFO:               numpy: 1.26.4
2024-11-25 19:59:07,531:INFO:              pandas: 1.5.3
2024-11-25 19:59:07,531:INFO:              jinja2: 3.1.4
2024-11-25 19:59:07,531:INFO:               scipy: 1.11.4
2024-11-25 19:59:07,531:INFO:              joblib: 1.3.2
2024-11-25 19:59:07,531:INFO:             sklearn: 1.4.2
2024-11-25 19:59:07,531:INFO:                pyod: 2.0.2
2024-11-25 19:59:07,532:INFO:            imblearn: 0.12.4
2024-11-25 19:59:07,532:INFO:   category_encoders: 2.6.4
2024-11-25 19:59:07,532:INFO:            lightgbm: 4.5.0
2024-11-25 19:59:07,532:INFO:               numba: 0.60.0
2024-11-25 19:59:07,532:INFO:            requests: 2.32.3
2024-11-25 19:59:07,532:INFO:          matplotlib: 3.8.4
2024-11-25 19:59:07,532:INFO:          scikitplot: 0.3.7
2024-11-25 19:59:07,532:INFO:         yellowbrick: 1.5
2024-11-25 19:59:07,532:INFO:              plotly: 5.22.0
2024-11-25 19:59:07,532:INFO:    plotly-resampler: Not installed
2024-11-25 19:59:07,532:INFO:             kaleido: 0.2.1
2024-11-25 19:59:07,532:INFO:           schemdraw: 0.15
2024-11-25 19:59:07,532:INFO:         statsmodels: 0.14.4
2024-11-25 19:59:07,533:INFO:              sktime: 0.26.0
2024-11-25 19:59:07,533:INFO:               tbats: 1.1.3
2024-11-25 19:59:07,533:INFO:            pmdarima: 2.0.4
2024-11-25 19:59:07,533:INFO:              psutil: 5.9.0
2024-11-25 19:59:07,533:INFO:          markupsafe: 2.1.3
2024-11-25 19:59:07,533:INFO:             pickle5: Not installed
2024-11-25 19:59:07,533:INFO:         cloudpickle: 3.0.0
2024-11-25 19:59:07,533:INFO:         deprecation: 2.1.0
2024-11-25 19:59:07,533:INFO:              xxhash: 3.5.0
2024-11-25 19:59:07,533:INFO:           wurlitzer: 3.1.1
2024-11-25 19:59:07,533:INFO:PyCaret optional dependencies:
2024-11-25 19:59:07,565:INFO:                shap: Not installed
2024-11-25 19:59:07,565:INFO:           interpret: Not installed
2024-11-25 19:59:07,565:INFO:                umap: Not installed
2024-11-25 19:59:07,565:INFO:     ydata_profiling: 0.0.dev0
2024-11-25 19:59:07,565:INFO:  explainerdashboard: Not installed
2024-11-25 19:59:07,565:INFO:             autoviz: Not installed
2024-11-25 19:59:07,566:INFO:           fairlearn: Not installed
2024-11-25 19:59:07,566:INFO:          deepchecks: Not installed
2024-11-25 19:59:07,566:INFO:             xgboost: Not installed
2024-11-25 19:59:07,566:INFO:            catboost: Not installed
2024-11-25 19:59:07,566:INFO:              kmodes: Not installed
2024-11-25 19:59:07,566:INFO:             mlxtend: Not installed
2024-11-25 19:59:07,566:INFO:       statsforecast: Not installed
2024-11-25 19:59:07,566:INFO:        tune_sklearn: Not installed
2024-11-25 19:59:07,566:INFO:                 ray: Not installed
2024-11-25 19:59:07,566:INFO:            hyperopt: Not installed
2024-11-25 19:59:07,566:INFO:              optuna: Not installed
2024-11-25 19:59:07,566:INFO:               skopt: Not installed
2024-11-25 19:59:07,567:INFO:              mlflow: Not installed
2024-11-25 19:59:07,567:INFO:              gradio: Not installed
2024-11-25 19:59:07,567:INFO:             fastapi: Not installed
2024-11-25 19:59:07,567:INFO:             uvicorn: Not installed
2024-11-25 19:59:07,567:INFO:              m2cgen: Not installed
2024-11-25 19:59:07,567:INFO:           evidently: Not installed
2024-11-25 19:59:07,567:INFO:               fugue: Not installed
2024-11-25 19:59:07,567:INFO:           streamlit: 1.37.1
2024-11-25 19:59:07,567:INFO:             prophet: Not installed
2024-11-25 19:59:07,567:INFO:None
2024-11-25 19:59:07,568:INFO:Set up data.
2024-11-25 19:59:07,574:INFO:Set up folding strategy.
2024-11-25 19:59:07,574:INFO:Set up train/test split.
2024-11-25 19:59:12,342:INFO:PyCaret ClassificationExperiment
2024-11-25 19:59:12,343:INFO:Logging name: clf-default-name
2024-11-25 19:59:12,344:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-25 19:59:12,344:INFO:version 3.3.1
2024-11-25 19:59:12,344:INFO:Initializing setup()
2024-11-25 19:59:12,344:INFO:self.USI: b783
2024-11-25 19:59:12,344:INFO:self._variable_keys: {'idx', 'exp_name_log', '_available_plots', 'USI', 'target_param', 'fold_generator', 'X_train', 'fold_shuffle_param', '_ml_usecase', 'is_multiclass', 'gpu_n_jobs_param', 'fold_groups_param', 'logging_param', 'seed', 'exp_id', 'X_test', 'pipeline', 'data', 'n_jobs_param', 'fix_imbalance', 'html_param', 'X', 'y_test', 'memory', 'y_train', 'log_plots_param', 'gpu_param', 'y'}
2024-11-25 19:59:12,344:INFO:Checking environment
2024-11-25 19:59:12,344:INFO:python_version: 3.11.9
2024-11-25 19:59:12,344:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-11-25 19:59:12,344:INFO:machine: AMD64
2024-11-25 19:59:12,344:INFO:platform: Windows-10-10.0.19045-SP0
2024-11-25 19:59:12,344:INFO:Memory: svmem(total=17107767296, available=8212910080, percent=52.0, used=8894857216, free=8212910080)
2024-11-25 19:59:12,345:INFO:Physical Core: 4
2024-11-25 19:59:12,345:INFO:Logical Core: 4
2024-11-25 19:59:12,345:INFO:Checking libraries
2024-11-25 19:59:12,345:INFO:System:
2024-11-25 19:59:12,345:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-11-25 19:59:12,345:INFO:executable: C:\Users\krzys\.conda\envs\datascience\python.exe
2024-11-25 19:59:12,345:INFO:   machine: Windows-10-10.0.19045-SP0
2024-11-25 19:59:12,345:INFO:PyCaret required dependencies:
2024-11-25 19:59:12,345:INFO:                 pip: 24.0
2024-11-25 19:59:12,345:INFO:          setuptools: 69.5.1
2024-11-25 19:59:12,345:INFO:             pycaret: 3.3.2
2024-11-25 19:59:12,346:INFO:             IPython: 8.25.0
2024-11-25 19:59:12,346:INFO:          ipywidgets: 7.8.1
2024-11-25 19:59:12,346:INFO:                tqdm: 4.66.5
2024-11-25 19:59:12,346:INFO:               numpy: 1.26.4
2024-11-25 19:59:12,346:INFO:              pandas: 1.5.3
2024-11-25 19:59:12,346:INFO:              jinja2: 3.1.4
2024-11-25 19:59:12,346:INFO:               scipy: 1.11.4
2024-11-25 19:59:12,346:INFO:              joblib: 1.3.2
2024-11-25 19:59:12,346:INFO:             sklearn: 1.4.2
2024-11-25 19:59:12,346:INFO:                pyod: 2.0.2
2024-11-25 19:59:12,346:INFO:            imblearn: 0.12.4
2024-11-25 19:59:12,346:INFO:   category_encoders: 2.6.4
2024-11-25 19:59:12,347:INFO:            lightgbm: 4.5.0
2024-11-25 19:59:12,347:INFO:               numba: 0.60.0
2024-11-25 19:59:12,347:INFO:            requests: 2.32.3
2024-11-25 19:59:12,347:INFO:          matplotlib: 3.8.4
2024-11-25 19:59:12,347:INFO:          scikitplot: 0.3.7
2024-11-25 19:59:12,347:INFO:         yellowbrick: 1.5
2024-11-25 19:59:12,347:INFO:              plotly: 5.22.0
2024-11-25 19:59:12,347:INFO:    plotly-resampler: Not installed
2024-11-25 19:59:12,347:INFO:             kaleido: 0.2.1
2024-11-25 19:59:12,347:INFO:           schemdraw: 0.15
2024-11-25 19:59:12,347:INFO:         statsmodels: 0.14.4
2024-11-25 19:59:12,347:INFO:              sktime: 0.26.0
2024-11-25 19:59:12,347:INFO:               tbats: 1.1.3
2024-11-25 19:59:12,348:INFO:            pmdarima: 2.0.4
2024-11-25 19:59:12,348:INFO:              psutil: 5.9.0
2024-11-25 19:59:12,348:INFO:          markupsafe: 2.1.3
2024-11-25 19:59:12,348:INFO:             pickle5: Not installed
2024-11-25 19:59:12,348:INFO:         cloudpickle: 3.0.0
2024-11-25 19:59:12,348:INFO:         deprecation: 2.1.0
2024-11-25 19:59:12,348:INFO:              xxhash: 3.5.0
2024-11-25 19:59:12,348:INFO:           wurlitzer: 3.1.1
2024-11-25 19:59:12,348:INFO:PyCaret optional dependencies:
2024-11-25 19:59:12,348:INFO:                shap: Not installed
2024-11-25 19:59:12,348:INFO:           interpret: Not installed
2024-11-25 19:59:12,348:INFO:                umap: Not installed
2024-11-25 19:59:12,349:INFO:     ydata_profiling: 0.0.dev0
2024-11-25 19:59:12,349:INFO:  explainerdashboard: Not installed
2024-11-25 19:59:12,349:INFO:             autoviz: Not installed
2024-11-25 19:59:12,349:INFO:           fairlearn: Not installed
2024-11-25 19:59:12,349:INFO:          deepchecks: Not installed
2024-11-25 19:59:12,349:INFO:             xgboost: Not installed
2024-11-25 19:59:12,349:INFO:            catboost: Not installed
2024-11-25 19:59:12,349:INFO:              kmodes: Not installed
2024-11-25 19:59:12,349:INFO:             mlxtend: Not installed
2024-11-25 19:59:12,349:INFO:       statsforecast: Not installed
2024-11-25 19:59:12,349:INFO:        tune_sklearn: Not installed
2024-11-25 19:59:12,349:INFO:                 ray: Not installed
2024-11-25 19:59:12,349:INFO:            hyperopt: Not installed
2024-11-25 19:59:12,350:INFO:              optuna: Not installed
2024-11-25 19:59:12,350:INFO:               skopt: Not installed
2024-11-25 19:59:12,350:INFO:              mlflow: Not installed
2024-11-25 19:59:12,350:INFO:              gradio: Not installed
2024-11-25 19:59:12,350:INFO:             fastapi: Not installed
2024-11-25 19:59:12,350:INFO:             uvicorn: Not installed
2024-11-25 19:59:12,351:INFO:              m2cgen: Not installed
2024-11-25 19:59:12,351:INFO:           evidently: Not installed
2024-11-25 19:59:12,351:INFO:               fugue: Not installed
2024-11-25 19:59:12,351:INFO:           streamlit: 1.37.1
2024-11-25 19:59:12,351:INFO:             prophet: Not installed
2024-11-25 19:59:12,351:INFO:None
2024-11-25 19:59:12,351:INFO:Set up data.
2024-11-25 19:59:12,354:INFO:Set up folding strategy.
2024-11-25 19:59:12,354:INFO:Set up train/test split.
2024-11-25 19:59:15,870:INFO:PyCaret ClassificationExperiment
2024-11-25 19:59:15,870:INFO:Logging name: clf-default-name
2024-11-25 19:59:15,871:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-25 19:59:15,871:INFO:version 3.3.1
2024-11-25 19:59:15,871:INFO:Initializing setup()
2024-11-25 19:59:15,871:INFO:self.USI: 80c7
2024-11-25 19:59:15,871:INFO:self._variable_keys: {'idx', 'exp_name_log', '_available_plots', 'USI', 'target_param', 'fold_generator', 'X_train', 'fold_shuffle_param', '_ml_usecase', 'is_multiclass', 'gpu_n_jobs_param', 'fold_groups_param', 'logging_param', 'seed', 'exp_id', 'X_test', 'pipeline', 'data', 'n_jobs_param', 'fix_imbalance', 'html_param', 'X', 'y_test', 'memory', 'y_train', 'log_plots_param', 'gpu_param', 'y'}
2024-11-25 19:59:15,871:INFO:Checking environment
2024-11-25 19:59:15,872:INFO:python_version: 3.11.9
2024-11-25 19:59:15,872:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-11-25 19:59:15,874:INFO:machine: AMD64
2024-11-25 19:59:15,875:INFO:platform: Windows-10-10.0.19045-SP0
2024-11-25 19:59:15,878:INFO:Memory: svmem(total=17107767296, available=8224636928, percent=51.9, used=8883130368, free=8224636928)
2024-11-25 19:59:15,880:INFO:Physical Core: 4
2024-11-25 19:59:15,880:INFO:Logical Core: 4
2024-11-25 19:59:15,880:INFO:Checking libraries
2024-11-25 19:59:15,881:INFO:System:
2024-11-25 19:59:15,881:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-11-25 19:59:15,881:INFO:executable: C:\Users\krzys\.conda\envs\datascience\python.exe
2024-11-25 19:59:15,881:INFO:   machine: Windows-10-10.0.19045-SP0
2024-11-25 19:59:15,882:INFO:PyCaret required dependencies:
2024-11-25 19:59:15,882:INFO:                 pip: 24.0
2024-11-25 19:59:15,882:INFO:          setuptools: 69.5.1
2024-11-25 19:59:15,882:INFO:             pycaret: 3.3.2
2024-11-25 19:59:15,882:INFO:             IPython: 8.25.0
2024-11-25 19:59:15,882:INFO:          ipywidgets: 7.8.1
2024-11-25 19:59:15,882:INFO:                tqdm: 4.66.5
2024-11-25 19:59:15,883:INFO:               numpy: 1.26.4
2024-11-25 19:59:15,883:INFO:              pandas: 1.5.3
2024-11-25 19:59:15,884:INFO:              jinja2: 3.1.4
2024-11-25 19:59:15,884:INFO:               scipy: 1.11.4
2024-11-25 19:59:15,884:INFO:              joblib: 1.3.2
2024-11-25 19:59:15,884:INFO:             sklearn: 1.4.2
2024-11-25 19:59:15,884:INFO:                pyod: 2.0.2
2024-11-25 19:59:15,884:INFO:            imblearn: 0.12.4
2024-11-25 19:59:15,884:INFO:   category_encoders: 2.6.4
2024-11-25 19:59:15,884:INFO:            lightgbm: 4.5.0
2024-11-25 19:59:15,884:INFO:               numba: 0.60.0
2024-11-25 19:59:15,886:INFO:            requests: 2.32.3
2024-11-25 19:59:15,886:INFO:          matplotlib: 3.8.4
2024-11-25 19:59:15,886:INFO:          scikitplot: 0.3.7
2024-11-25 19:59:15,886:INFO:         yellowbrick: 1.5
2024-11-25 19:59:15,888:INFO:              plotly: 5.22.0
2024-11-25 19:59:15,889:INFO:    plotly-resampler: Not installed
2024-11-25 19:59:15,889:INFO:             kaleido: 0.2.1
2024-11-25 19:59:15,889:INFO:           schemdraw: 0.15
2024-11-25 19:59:15,890:INFO:         statsmodels: 0.14.4
2024-11-25 19:59:15,890:INFO:              sktime: 0.26.0
2024-11-25 19:59:15,890:INFO:               tbats: 1.1.3
2024-11-25 19:59:15,890:INFO:            pmdarima: 2.0.4
2024-11-25 19:59:15,891:INFO:              psutil: 5.9.0
2024-11-25 19:59:15,891:INFO:          markupsafe: 2.1.3
2024-11-25 19:59:15,892:INFO:             pickle5: Not installed
2024-11-25 19:59:15,892:INFO:         cloudpickle: 3.0.0
2024-11-25 19:59:15,892:INFO:         deprecation: 2.1.0
2024-11-25 19:59:15,892:INFO:              xxhash: 3.5.0
2024-11-25 19:59:15,892:INFO:           wurlitzer: 3.1.1
2024-11-25 19:59:15,893:INFO:PyCaret optional dependencies:
2024-11-25 19:59:15,893:INFO:                shap: Not installed
2024-11-25 19:59:15,893:INFO:           interpret: Not installed
2024-11-25 19:59:15,893:INFO:                umap: Not installed
2024-11-25 19:59:15,894:INFO:     ydata_profiling: 0.0.dev0
2024-11-25 19:59:15,894:INFO:  explainerdashboard: Not installed
2024-11-25 19:59:15,894:INFO:             autoviz: Not installed
2024-11-25 19:59:15,894:INFO:           fairlearn: Not installed
2024-11-25 19:59:15,894:INFO:          deepchecks: Not installed
2024-11-25 19:59:15,894:INFO:             xgboost: Not installed
2024-11-25 19:59:15,895:INFO:            catboost: Not installed
2024-11-25 19:59:15,895:INFO:              kmodes: Not installed
2024-11-25 19:59:15,895:INFO:             mlxtend: Not installed
2024-11-25 19:59:15,895:INFO:       statsforecast: Not installed
2024-11-25 19:59:15,895:INFO:        tune_sklearn: Not installed
2024-11-25 19:59:15,895:INFO:                 ray: Not installed
2024-11-25 19:59:15,896:INFO:            hyperopt: Not installed
2024-11-25 19:59:15,896:INFO:              optuna: Not installed
2024-11-25 19:59:15,896:INFO:               skopt: Not installed
2024-11-25 19:59:15,896:INFO:              mlflow: Not installed
2024-11-25 19:59:15,896:INFO:              gradio: Not installed
2024-11-25 19:59:15,897:INFO:             fastapi: Not installed
2024-11-25 19:59:15,897:INFO:             uvicorn: Not installed
2024-11-25 19:59:15,897:INFO:              m2cgen: Not installed
2024-11-25 19:59:15,897:INFO:           evidently: Not installed
2024-11-25 19:59:15,897:INFO:               fugue: Not installed
2024-11-25 19:59:15,897:INFO:           streamlit: 1.37.1
2024-11-25 19:59:15,898:INFO:             prophet: Not installed
2024-11-25 19:59:15,898:INFO:None
2024-11-25 19:59:15,898:INFO:Set up data.
2024-11-25 19:59:15,906:INFO:Set up folding strategy.
2024-11-25 19:59:15,906:INFO:Set up train/test split.
2024-11-25 19:59:19,659:INFO:PyCaret ClassificationExperiment
2024-11-25 19:59:19,661:INFO:Logging name: clf-default-name
2024-11-25 19:59:19,661:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-25 19:59:19,661:INFO:version 3.3.1
2024-11-25 19:59:19,661:INFO:Initializing setup()
2024-11-25 19:59:19,661:INFO:self.USI: 6531
2024-11-25 19:59:19,662:INFO:self._variable_keys: {'idx', 'exp_name_log', '_available_plots', 'USI', 'target_param', 'fold_generator', 'X_train', 'fold_shuffle_param', '_ml_usecase', 'is_multiclass', 'gpu_n_jobs_param', 'fold_groups_param', 'logging_param', 'seed', 'exp_id', 'X_test', 'pipeline', 'data', 'n_jobs_param', 'fix_imbalance', 'html_param', 'X', 'y_test', 'memory', 'y_train', 'log_plots_param', 'gpu_param', 'y'}
2024-11-25 19:59:19,662:INFO:Checking environment
2024-11-25 19:59:19,662:INFO:python_version: 3.11.9
2024-11-25 19:59:19,662:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-11-25 19:59:19,662:INFO:machine: AMD64
2024-11-25 19:59:19,662:INFO:platform: Windows-10-10.0.19045-SP0
2024-11-25 19:59:19,663:INFO:Memory: svmem(total=17107767296, available=8218951680, percent=52.0, used=8888815616, free=8218951680)
2024-11-25 19:59:19,663:INFO:Physical Core: 4
2024-11-25 19:59:19,663:INFO:Logical Core: 4
2024-11-25 19:59:19,663:INFO:Checking libraries
2024-11-25 19:59:19,663:INFO:System:
2024-11-25 19:59:19,663:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-11-25 19:59:19,663:INFO:executable: C:\Users\krzys\.conda\envs\datascience\python.exe
2024-11-25 19:59:19,663:INFO:   machine: Windows-10-10.0.19045-SP0
2024-11-25 19:59:19,663:INFO:PyCaret required dependencies:
2024-11-25 19:59:19,664:INFO:                 pip: 24.0
2024-11-25 19:59:19,664:INFO:          setuptools: 69.5.1
2024-11-25 19:59:19,664:INFO:             pycaret: 3.3.2
2024-11-25 19:59:19,664:INFO:             IPython: 8.25.0
2024-11-25 19:59:19,664:INFO:          ipywidgets: 7.8.1
2024-11-25 19:59:19,664:INFO:                tqdm: 4.66.5
2024-11-25 19:59:19,664:INFO:               numpy: 1.26.4
2024-11-25 19:59:19,664:INFO:              pandas: 1.5.3
2024-11-25 19:59:19,664:INFO:              jinja2: 3.1.4
2024-11-25 19:59:19,665:INFO:               scipy: 1.11.4
2024-11-25 19:59:19,665:INFO:              joblib: 1.3.2
2024-11-25 19:59:19,665:INFO:             sklearn: 1.4.2
2024-11-25 19:59:19,665:INFO:                pyod: 2.0.2
2024-11-25 19:59:19,665:INFO:            imblearn: 0.12.4
2024-11-25 19:59:19,665:INFO:   category_encoders: 2.6.4
2024-11-25 19:59:19,665:INFO:            lightgbm: 4.5.0
2024-11-25 19:59:19,665:INFO:               numba: 0.60.0
2024-11-25 19:59:19,666:INFO:            requests: 2.32.3
2024-11-25 19:59:19,666:INFO:          matplotlib: 3.8.4
2024-11-25 19:59:19,666:INFO:          scikitplot: 0.3.7
2024-11-25 19:59:19,666:INFO:         yellowbrick: 1.5
2024-11-25 19:59:19,666:INFO:              plotly: 5.22.0
2024-11-25 19:59:19,666:INFO:    plotly-resampler: Not installed
2024-11-25 19:59:19,666:INFO:             kaleido: 0.2.1
2024-11-25 19:59:19,667:INFO:           schemdraw: 0.15
2024-11-25 19:59:19,667:INFO:         statsmodels: 0.14.4
2024-11-25 19:59:19,668:INFO:              sktime: 0.26.0
2024-11-25 19:59:19,668:INFO:               tbats: 1.1.3
2024-11-25 19:59:19,668:INFO:            pmdarima: 2.0.4
2024-11-25 19:59:19,668:INFO:              psutil: 5.9.0
2024-11-25 19:59:19,668:INFO:          markupsafe: 2.1.3
2024-11-25 19:59:19,668:INFO:             pickle5: Not installed
2024-11-25 19:59:19,668:INFO:         cloudpickle: 3.0.0
2024-11-25 19:59:19,668:INFO:         deprecation: 2.1.0
2024-11-25 19:59:19,669:INFO:              xxhash: 3.5.0
2024-11-25 19:59:19,669:INFO:           wurlitzer: 3.1.1
2024-11-25 19:59:19,669:INFO:PyCaret optional dependencies:
2024-11-25 19:59:19,669:INFO:                shap: Not installed
2024-11-25 19:59:19,669:INFO:           interpret: Not installed
2024-11-25 19:59:19,669:INFO:                umap: Not installed
2024-11-25 19:59:19,669:INFO:     ydata_profiling: 0.0.dev0
2024-11-25 19:59:19,669:INFO:  explainerdashboard: Not installed
2024-11-25 19:59:19,669:INFO:             autoviz: Not installed
2024-11-25 19:59:19,669:INFO:           fairlearn: Not installed
2024-11-25 19:59:19,669:INFO:          deepchecks: Not installed
2024-11-25 19:59:19,669:INFO:             xgboost: Not installed
2024-11-25 19:59:19,670:INFO:            catboost: Not installed
2024-11-25 19:59:19,670:INFO:              kmodes: Not installed
2024-11-25 19:59:19,670:INFO:             mlxtend: Not installed
2024-11-25 19:59:19,670:INFO:       statsforecast: Not installed
2024-11-25 19:59:19,670:INFO:        tune_sklearn: Not installed
2024-11-25 19:59:19,670:INFO:                 ray: Not installed
2024-11-25 19:59:19,670:INFO:            hyperopt: Not installed
2024-11-25 19:59:19,670:INFO:              optuna: Not installed
2024-11-25 19:59:19,670:INFO:               skopt: Not installed
2024-11-25 19:59:19,670:INFO:              mlflow: Not installed
2024-11-25 19:59:19,670:INFO:              gradio: Not installed
2024-11-25 19:59:19,670:INFO:             fastapi: Not installed
2024-11-25 19:59:19,671:INFO:             uvicorn: Not installed
2024-11-25 19:59:19,671:INFO:              m2cgen: Not installed
2024-11-25 19:59:19,671:INFO:           evidently: Not installed
2024-11-25 19:59:19,671:INFO:               fugue: Not installed
2024-11-25 19:59:19,671:INFO:           streamlit: 1.37.1
2024-11-25 19:59:19,671:INFO:             prophet: Not installed
2024-11-25 19:59:19,671:INFO:None
2024-11-25 19:59:19,671:INFO:Set up data.
2024-11-25 19:59:19,680:INFO:Set up folding strategy.
2024-11-25 19:59:19,680:INFO:Set up train/test split.
2024-11-25 19:59:19,686:INFO:Set up index.
2024-11-25 19:59:19,686:INFO:Assigning column types.
2024-11-25 19:59:19,692:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-25 19:59:19,780:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-25 19:59:19,785:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-25 19:59:19,841:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 19:59:19,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 19:59:19,919:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-25 19:59:19,920:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-25 19:59:19,971:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 19:59:19,972:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 19:59:19,973:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-25 19:59:20,053:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-25 19:59:20,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 19:59:20,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 19:59:20,186:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-25 19:59:20,237:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 19:59:20,237:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 19:59:20,238:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-25 19:59:20,389:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 19:59:20,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 19:59:20,539:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 19:59:20,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 19:59:20,545:INFO:Preparing preprocessing pipeline...
2024-11-25 19:59:20,546:INFO:Set up label encoding.
2024-11-25 19:59:20,547:INFO:Set up simple imputation.
2024-11-25 19:59:20,550:INFO:Set up encoding of categorical features.
2024-11-25 19:59:20,550:INFO:Set up column name cleaning.
2024-11-25 19:59:20,709:INFO:Finished creating preprocessing pipeline.
2024-11-25 19:59:20,722:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\krzys\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Experience (years)', 'Salary'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=Non...
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Address',
                                                                    'Email'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-11-25 19:59:20,723:INFO:Creating final display dataframe.
2024-11-25 19:59:21,103:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                123
1                        Target                                                Job
2                   Target type                                         Multiclass
3                Target mapping  Artist: 0, Doctor: 1, Engineer: 2, Lawyer: 3, ...
4           Original data shape                                            (62, 6)
5        Transformed data shape                                            (62, 6)
6   Transformed train set shape                                            (43, 6)
7    Transformed test set shape                                            (19, 6)
8              Numeric features                                                  2
9          Categorical features                                                  3
10                   Preprocess                                               True
11              Imputation type                                             simple
12           Numeric imputation                                               mean
13       Categorical imputation                                               mode
14     Maximum one-hot encoding                                                 25
15              Encoding method                                               None
16               Fold Generator                                    StratifiedKFold
17                  Fold Number                                                 10
18                     CPU Jobs                                                 -1
19                      Use GPU                                              False
20               Log Experiment                                              False
21              Experiment Name                                   clf-default-name
22                          USI                                               6531
2024-11-25 19:59:21,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 19:59:21,266:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 19:59:21,402:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 19:59:21,402:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 19:59:21,404:INFO:setup() successfully completed in 1.75s...............
2024-11-25 19:59:21,404:INFO:Initializing compare_models()
2024-11-25 19:59:21,404:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-11-25 19:59:21,404:INFO:Checking exceptions
2024-11-25 19:59:21,408:INFO:Preparing display monitor
2024-11-25 19:59:21,417:INFO:Initializing Logistic Regression
2024-11-25 19:59:21,417:INFO:Total runtime is 0.0 minutes
2024-11-25 19:59:21,417:INFO:SubProcess create_model() called ==================================
2024-11-25 19:59:21,417:INFO:Initializing create_model()
2024-11-25 19:59:21,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B316E1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 19:59:21,418:INFO:Checking exceptions
2024-11-25 19:59:21,418:INFO:Importing libraries
2024-11-25 19:59:21,418:INFO:Copying training dataset
2024-11-25 19:59:21,425:INFO:Defining folds
2024-11-25 19:59:21,426:INFO:Declaring metric variables
2024-11-25 19:59:21,426:INFO:Importing untrained model
2024-11-25 19:59:21,427:INFO:Logistic Regression Imported successfully
2024-11-25 19:59:21,427:INFO:Starting cross validation
2024-11-25 19:59:21,428:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 19:59:21,450:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2024-11-25 19:59:26,568:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-25 19:59:26,576:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-25 19:59:26,605:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:26,609:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:26,614:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:26,614:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:26,617:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:26,618:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:26,620:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:26,622:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:26,625:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:26,627:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:26,631:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-25 19:59:26,671:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:26,674:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:26,680:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:26,682:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:26,685:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:26,782:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-25 19:59:26,821:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:26,826:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:26,828:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:26,830:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:26,832:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:26,835:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:26,838:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:26,985:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-25 19:59:26,999:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-25 19:59:27,018:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:27,020:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,022:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,025:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,028:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,030:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,032:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,036:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:27,038:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-25 19:59:27,042:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,044:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,046:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,048:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,051:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,054:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,073:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:27,075:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,077:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,080:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,082:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,084:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,087:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,201:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-25 19:59:27,237:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:27,241:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,242:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,244:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,246:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,249:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,250:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,301:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-25 19:59:27,333:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:27,335:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,337:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-25 19:59:27,338:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,340:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,341:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,343:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,368:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:27,370:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,372:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,375:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,377:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,379:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,380:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,387:INFO:Calculating mean and std
2024-11-25 19:59:27,388:INFO:Creating metrics dataframe
2024-11-25 19:59:27,390:INFO:Uploading results into container
2024-11-25 19:59:27,391:INFO:Uploading model into container now
2024-11-25 19:59:27,391:INFO:_master_model_container: 1
2024-11-25 19:59:27,391:INFO:_display_container: 2
2024-11-25 19:59:27,392:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-25 19:59:27,392:INFO:create_model() successfully completed......................................
2024-11-25 19:59:27,504:INFO:SubProcess create_model() end ==================================
2024-11-25 19:59:27,505:INFO:Creating metrics dataframe
2024-11-25 19:59:27,506:INFO:Initializing K Neighbors Classifier
2024-11-25 19:59:27,506:INFO:Total runtime is 0.10148310661315918 minutes
2024-11-25 19:59:27,506:INFO:SubProcess create_model() called ==================================
2024-11-25 19:59:27,506:INFO:Initializing create_model()
2024-11-25 19:59:27,506:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B316E1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 19:59:27,506:INFO:Checking exceptions
2024-11-25 19:59:27,506:INFO:Importing libraries
2024-11-25 19:59:27,506:INFO:Copying training dataset
2024-11-25 19:59:27,511:INFO:Defining folds
2024-11-25 19:59:27,511:INFO:Declaring metric variables
2024-11-25 19:59:27,511:INFO:Importing untrained model
2024-11-25 19:59:27,516:INFO:K Neighbors Classifier Imported successfully
2024-11-25 19:59:27,516:INFO:Starting cross validation
2024-11-25 19:59:27,518:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 19:59:27,522:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2024-11-25 19:59:27,702:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:27,704:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:27,706:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,708:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,711:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,713:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,713:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,716:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,716:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,721:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:27,723:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,724:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:27,727:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,733:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,736:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,736:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,738:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,739:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,740:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,742:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,840:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:27,842:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,844:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,847:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,849:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,854:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,858:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,858:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:27,858:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:27,862:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,863:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:27,863:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,863:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,865:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,867:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,867:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,867:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,869:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,870:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,871:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,871:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,871:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,873:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,874:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,874:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,876:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,973:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:27,975:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,977:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,979:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,980:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:27,981:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,982:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,983:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,984:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,985:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,987:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,989:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:27,991:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:27,998:INFO:Calculating mean and std
2024-11-25 19:59:27,999:INFO:Creating metrics dataframe
2024-11-25 19:59:28,002:INFO:Uploading results into container
2024-11-25 19:59:28,002:INFO:Uploading model into container now
2024-11-25 19:59:28,003:INFO:_master_model_container: 2
2024-11-25 19:59:28,003:INFO:_display_container: 2
2024-11-25 19:59:28,003:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-25 19:59:28,003:INFO:create_model() successfully completed......................................
2024-11-25 19:59:28,113:INFO:SubProcess create_model() end ==================================
2024-11-25 19:59:28,113:INFO:Creating metrics dataframe
2024-11-25 19:59:28,117:INFO:Initializing Naive Bayes
2024-11-25 19:59:28,117:INFO:Total runtime is 0.1116617242495219 minutes
2024-11-25 19:59:28,117:INFO:SubProcess create_model() called ==================================
2024-11-25 19:59:28,118:INFO:Initializing create_model()
2024-11-25 19:59:28,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B316E1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 19:59:28,118:INFO:Checking exceptions
2024-11-25 19:59:28,118:INFO:Importing libraries
2024-11-25 19:59:28,118:INFO:Copying training dataset
2024-11-25 19:59:28,123:INFO:Defining folds
2024-11-25 19:59:28,124:INFO:Declaring metric variables
2024-11-25 19:59:28,124:INFO:Importing untrained model
2024-11-25 19:59:28,125:INFO:Naive Bayes Imported successfully
2024-11-25 19:59:28,125:INFO:Starting cross validation
2024-11-25 19:59:28,127:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 19:59:28,130:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2024-11-25 19:59:28,255:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:28,256:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:28,258:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:28,258:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,259:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,260:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,261:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,261:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,261:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,261:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,261:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,267:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,268:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,269:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,269:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,276:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:28,285:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,287:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,290:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,294:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,296:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,298:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,376:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:28,378:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,379:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:28,380:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,381:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:28,382:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,382:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,383:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,384:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,384:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,386:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,387:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,388:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,388:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,389:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,390:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,392:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,392:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,418:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:28,421:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,423:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,427:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,428:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,431:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,433:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,495:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:28,497:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,498:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:28,499:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,501:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,501:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,502:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,503:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,504:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,506:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,507:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,508:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,509:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,516:INFO:Calculating mean and std
2024-11-25 19:59:28,517:INFO:Creating metrics dataframe
2024-11-25 19:59:28,519:INFO:Uploading results into container
2024-11-25 19:59:28,520:INFO:Uploading model into container now
2024-11-25 19:59:28,520:INFO:_master_model_container: 3
2024-11-25 19:59:28,521:INFO:_display_container: 2
2024-11-25 19:59:28,521:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-25 19:59:28,521:INFO:create_model() successfully completed......................................
2024-11-25 19:59:28,632:INFO:SubProcess create_model() end ==================================
2024-11-25 19:59:28,632:INFO:Creating metrics dataframe
2024-11-25 19:59:28,636:INFO:Initializing Decision Tree Classifier
2024-11-25 19:59:28,636:INFO:Total runtime is 0.12030774354934692 minutes
2024-11-25 19:59:28,636:INFO:SubProcess create_model() called ==================================
2024-11-25 19:59:28,637:INFO:Initializing create_model()
2024-11-25 19:59:28,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B316E1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 19:59:28,637:INFO:Checking exceptions
2024-11-25 19:59:28,637:INFO:Importing libraries
2024-11-25 19:59:28,637:INFO:Copying training dataset
2024-11-25 19:59:28,642:INFO:Defining folds
2024-11-25 19:59:28,642:INFO:Declaring metric variables
2024-11-25 19:59:28,643:INFO:Importing untrained model
2024-11-25 19:59:28,643:INFO:Decision Tree Classifier Imported successfully
2024-11-25 19:59:28,644:INFO:Starting cross validation
2024-11-25 19:59:28,645:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 19:59:28,649:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2024-11-25 19:59:28,768:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:28,770:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:28,770:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,773:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,775:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:28,776:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,777:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,777:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,778:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,779:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,780:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,781:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,782:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,783:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,787:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,792:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:28,794:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,801:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,803:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,805:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,808:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,811:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,890:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:28,893:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,895:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,896:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:28,897:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,899:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,899:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,901:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,902:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:28,902:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,903:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,904:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,905:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,907:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,908:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,909:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,911:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,913:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,921:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:28,923:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,925:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,928:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:28,931:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:28,934:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,006:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:29,008:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,011:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,011:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:29,014:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,015:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,016:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,016:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,018:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,018:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,020:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,020:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,022:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,024:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,030:INFO:Calculating mean and std
2024-11-25 19:59:29,031:INFO:Creating metrics dataframe
2024-11-25 19:59:29,033:INFO:Uploading results into container
2024-11-25 19:59:29,034:INFO:Uploading model into container now
2024-11-25 19:59:29,034:INFO:_master_model_container: 4
2024-11-25 19:59:29,034:INFO:_display_container: 2
2024-11-25 19:59:29,035:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-11-25 19:59:29,035:INFO:create_model() successfully completed......................................
2024-11-25 19:59:29,147:INFO:SubProcess create_model() end ==================================
2024-11-25 19:59:29,148:INFO:Creating metrics dataframe
2024-11-25 19:59:29,151:INFO:Initializing SVM - Linear Kernel
2024-11-25 19:59:29,152:INFO:Total runtime is 0.12890435457229615 minutes
2024-11-25 19:59:29,152:INFO:SubProcess create_model() called ==================================
2024-11-25 19:59:29,152:INFO:Initializing create_model()
2024-11-25 19:59:29,152:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B316E1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 19:59:29,152:INFO:Checking exceptions
2024-11-25 19:59:29,153:INFO:Importing libraries
2024-11-25 19:59:29,153:INFO:Copying training dataset
2024-11-25 19:59:29,157:INFO:Defining folds
2024-11-25 19:59:29,157:INFO:Declaring metric variables
2024-11-25 19:59:29,157:INFO:Importing untrained model
2024-11-25 19:59:29,158:INFO:SVM - Linear Kernel Imported successfully
2024-11-25 19:59:29,159:INFO:Starting cross validation
2024-11-25 19:59:29,161:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 19:59:29,164:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2024-11-25 19:59:29,296:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:29,297:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:29,299:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,300:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:29,300:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,302:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,303:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,304:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,305:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,308:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

 f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,308:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,309:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,310:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,312:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,337:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:29,339:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,341:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,344:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,347:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,350:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,352:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,433:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:29,434:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:29,435:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,436:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,437:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,437:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:29,442:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,442:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,443:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,444:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,444:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,445:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,446:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,447:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,447:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,448:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,449:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,449:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,451:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,481:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:29,484:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,486:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,489:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,491:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,495:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,497:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,556:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:29,559:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:29,560:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,562:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

ic.capitalize()} is", len(result))

2024-11-25 19:59:29,563:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,564:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,565:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,566:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,567:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,568:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,569:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,570:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,577:INFO:Calculating mean and std
2024-11-25 19:59:29,578:INFO:Creating metrics dataframe
2024-11-25 19:59:29,580:INFO:Uploading results into container
2024-11-25 19:59:29,581:INFO:Uploading model into container now
2024-11-25 19:59:29,581:INFO:_master_model_container: 5
2024-11-25 19:59:29,582:INFO:_display_container: 2
2024-11-25 19:59:29,582:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-25 19:59:29,582:INFO:create_model() successfully completed......................................
2024-11-25 19:59:29,693:INFO:SubProcess create_model() end ==================================
2024-11-25 19:59:29,694:INFO:Creating metrics dataframe
2024-11-25 19:59:29,697:INFO:Initializing Ridge Classifier
2024-11-25 19:59:29,697:INFO:Total runtime is 0.13800166845321657 minutes
2024-11-25 19:59:29,698:INFO:SubProcess create_model() called ==================================
2024-11-25 19:59:29,698:INFO:Initializing create_model()
2024-11-25 19:59:29,698:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B316E1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 19:59:29,698:INFO:Checking exceptions
2024-11-25 19:59:29,698:INFO:Importing libraries
2024-11-25 19:59:29,698:INFO:Copying training dataset
2024-11-25 19:59:29,703:INFO:Defining folds
2024-11-25 19:59:29,703:INFO:Declaring metric variables
2024-11-25 19:59:29,703:INFO:Importing untrained model
2024-11-25 19:59:29,704:INFO:Ridge Classifier Imported successfully
2024-11-25 19:59:29,704:INFO:Starting cross validation
2024-11-25 19:59:29,706:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 19:59:29,710:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2024-11-25 19:59:29,837:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:29,837:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:29,840:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:29,840:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,842:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,842:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,844:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,845:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,846:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,847:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,848:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,848:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,849:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,850:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,869:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:29,871:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,873:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,876:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,878:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,882:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,884:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,964:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:29,966:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:29,966:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,968:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,968:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,969:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:29,970:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,970:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,972:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,972:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,974:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,975:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,976:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

lt))

2024-11-25 19:59:29,978:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,980:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,980:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,982:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:29,985:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:29,996:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:30,000:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,002:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:30,004:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,006:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:30,008:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,011:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:30,080:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:30,083:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,083:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:30,085:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:30,085:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,087:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,087:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:30,088:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:30,089:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,091:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,091:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:30,094:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,101:INFO:Calculating mean and std
2024-11-25 19:59:30,102:INFO:Creating metrics dataframe
2024-11-25 19:59:30,104:INFO:Uploading results into container
2024-11-25 19:59:30,105:INFO:Uploading model into container now
2024-11-25 19:59:30,105:INFO:_master_model_container: 6
2024-11-25 19:59:30,105:INFO:_display_container: 2
2024-11-25 19:59:30,106:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-25 19:59:30,106:INFO:create_model() successfully completed......................................
2024-11-25 19:59:30,216:INFO:SubProcess create_model() end ==================================
2024-11-25 19:59:30,217:INFO:Creating metrics dataframe
2024-11-25 19:59:30,220:INFO:Initializing Random Forest Classifier
2024-11-25 19:59:30,220:INFO:Total runtime is 0.14671407938003542 minutes
2024-11-25 19:59:30,220:INFO:SubProcess create_model() called ==================================
2024-11-25 19:59:30,221:INFO:Initializing create_model()
2024-11-25 19:59:30,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B316E1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 19:59:30,221:INFO:Checking exceptions
2024-11-25 19:59:30,221:INFO:Importing libraries
2024-11-25 19:59:30,221:INFO:Copying training dataset
2024-11-25 19:59:30,225:INFO:Defining folds
2024-11-25 19:59:30,226:INFO:Declaring metric variables
2024-11-25 19:59:30,227:INFO:Importing untrained model
2024-11-25 19:59:30,227:INFO:Random Forest Classifier Imported successfully
2024-11-25 19:59:30,228:INFO:Starting cross validation
2024-11-25 19:59:30,229:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 19:59:30,233:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2024-11-25 19:59:30,591:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:30,594:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,596:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:30,598:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,598:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,602:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:30,604:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,605:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,605:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:30,606:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:30,608:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,608:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,613:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,616:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:30,618:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,650:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:30,652:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,655:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:30,657:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,659:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:30,661:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,663:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:30,965:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:30,966:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:30,967:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,969:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:30,972:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,970:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,975:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:30,975:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:30,976:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:30,977:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,977:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,979:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:30,979:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,981:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,981:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:30,983:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:30,985:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:30,989:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,064:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:31,066:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,069:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,071:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,073:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,075:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,311:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:31,311:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:31,316:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,318:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,318:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,320:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,321:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,322:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,322:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,324:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,325:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,326:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,326:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,328:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,335:INFO:Calculating mean and std
2024-11-25 19:59:31,336:INFO:Creating metrics dataframe
2024-11-25 19:59:31,338:INFO:Uploading results into container
2024-11-25 19:59:31,339:INFO:Uploading model into container now
2024-11-25 19:59:31,339:INFO:_master_model_container: 7
2024-11-25 19:59:31,339:INFO:_display_container: 2
2024-11-25 19:59:31,340:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-11-25 19:59:31,340:INFO:create_model() successfully completed......................................
2024-11-25 19:59:31,463:INFO:SubProcess create_model() end ==================================
2024-11-25 19:59:31,463:INFO:Creating metrics dataframe
2024-11-25 19:59:31,470:INFO:Initializing Quadratic Discriminant Analysis
2024-11-25 19:59:31,470:INFO:Total runtime is 0.16754382451375327 minutes
2024-11-25 19:59:31,472:INFO:SubProcess create_model() called ==================================
2024-11-25 19:59:31,473:INFO:Initializing create_model()
2024-11-25 19:59:31,473:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B316E1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 19:59:31,473:INFO:Checking exceptions
2024-11-25 19:59:31,473:INFO:Importing libraries
2024-11-25 19:59:31,473:INFO:Copying training dataset
2024-11-25 19:59:31,479:INFO:Defining folds
2024-11-25 19:59:31,481:INFO:Declaring metric variables
2024-11-25 19:59:31,484:INFO:Importing untrained model
2024-11-25 19:59:31,484:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-25 19:59:31,486:INFO:Starting cross validation
2024-11-25 19:59:31,488:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 19:59:31,492:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2024-11-25 19:59:31,577:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-25 19:59:31,581:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-25 19:59:31,581:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-25 19:59:31,599:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-25 19:59:31,608:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,608:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,608:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,608:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,608:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,608:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,608:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,609:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,609:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,612:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,612:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,612:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,613:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,613:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,613:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,614:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,614:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,614:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,618:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-11-25 19:59:31,618:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-11-25 19:59:31,618:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-11-25 19:59:31,620:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,620:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,624:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,624:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,626:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,627:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,627:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,629:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,630:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,630:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,632:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,632:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,633:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,637:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,637:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,637:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,647:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-11-25 19:59:31,649:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,651:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,656:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,658:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,660:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,662:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,703:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-25 19:59:31,705:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-25 19:59:31,713:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-25 19:59:31,737:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,738:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,738:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,739:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,739:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,739:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,741:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-25 19:59:31,741:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,742:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,742:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,742:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,742:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,742:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,743:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,743:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,743:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,745:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-11-25 19:59:31,745:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,746:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,746:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,746:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-11-25 19:59:31,749:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,750:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-11-25 19:59:31,750:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,751:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,752:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,752:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,753:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

ic.capitalize()} is", len(result))

2024-11-25 19:59:31,755:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,755:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,756:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,757:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,757:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,757:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,759:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,759:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,760:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,762:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,762:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,769:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,769:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,769:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,773:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,774:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,774:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,777:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-11-25 19:59:31,779:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,781:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,783:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,786:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,789:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,791:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,828:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-25 19:59:31,832:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-25 19:59:31,854:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,854:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,854:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,857:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,858:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,858:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,858:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,858:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,859:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,861:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-11-25 19:59:31,862:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,862:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-11-25 19:59:31,862:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-11-25 19:59:31,863:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,864:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,865:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-11-25 19:59:31,868:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,868:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,870:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,870:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,872:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,872:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,874:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,874:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,876:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:31,878:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:31,884:INFO:Calculating mean and std
2024-11-25 19:59:31,885:INFO:Creating metrics dataframe
2024-11-25 19:59:31,887:INFO:Uploading results into container
2024-11-25 19:59:31,888:INFO:Uploading model into container now
2024-11-25 19:59:31,888:INFO:_master_model_container: 8
2024-11-25 19:59:31,888:INFO:_display_container: 2
2024-11-25 19:59:31,889:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-25 19:59:31,889:INFO:create_model() successfully completed......................................
2024-11-25 19:59:31,999:INFO:SubProcess create_model() end ==================================
2024-11-25 19:59:31,999:INFO:Creating metrics dataframe
2024-11-25 19:59:32,004:INFO:Initializing Ada Boost Classifier
2024-11-25 19:59:32,004:INFO:Total runtime is 0.1764387329419454 minutes
2024-11-25 19:59:32,004:INFO:SubProcess create_model() called ==================================
2024-11-25 19:59:32,005:INFO:Initializing create_model()
2024-11-25 19:59:32,005:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B316E1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 19:59:32,005:INFO:Checking exceptions
2024-11-25 19:59:32,005:INFO:Importing libraries
2024-11-25 19:59:32,005:INFO:Copying training dataset
2024-11-25 19:59:32,009:INFO:Defining folds
2024-11-25 19:59:32,009:INFO:Declaring metric variables
2024-11-25 19:59:32,009:INFO:Importing untrained model
2024-11-25 19:59:32,010:INFO:Ada Boost Classifier Imported successfully
2024-11-25 19:59:32,010:INFO:Starting cross validation
2024-11-25 19:59:32,012:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 19:59:32,016:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2024-11-25 19:59:32,100:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 19:59:32,101:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 19:59:32,104:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 19:59:32,125:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 19:59:32,271:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:32,274:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,274:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:32,276:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,277:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:32,277:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,281:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,282:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,280:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,284:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,284:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,287:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,287:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,289:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,291:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,306:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:32,310:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,312:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,315:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,317:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,319:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,322:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,364:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 19:59:32,365:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 19:59:32,372:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 19:59:32,399:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 19:59:32,534:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:32,537:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,539:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,540:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:32,542:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,542:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,544:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,544:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,545:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:32,546:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,546:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,548:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,549:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,550:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,552:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,552:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,555:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,556:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,561:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,561:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,614:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:32,618:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,621:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,621:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,621:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,631:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,631:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,706:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 19:59:32,712:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 19:59:32,866:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:32,869:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,870:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:32,871:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,873:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,873:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,875:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,875:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,877:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,877:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,879:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,879:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,882:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:32,884:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:32,889:INFO:Calculating mean and std
2024-11-25 19:59:32,890:INFO:Creating metrics dataframe
2024-11-25 19:59:32,892:INFO:Uploading results into container
2024-11-25 19:59:32,893:INFO:Uploading model into container now
2024-11-25 19:59:32,893:INFO:_master_model_container: 9
2024-11-25 19:59:32,894:INFO:_display_container: 2
2024-11-25 19:59:32,894:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-11-25 19:59:32,894:INFO:create_model() successfully completed......................................
2024-11-25 19:59:33,004:INFO:SubProcess create_model() end ==================================
2024-11-25 19:59:33,004:INFO:Creating metrics dataframe
2024-11-25 19:59:33,007:INFO:Initializing Gradient Boosting Classifier
2024-11-25 19:59:33,007:INFO:Total runtime is 0.1931677261988322 minutes
2024-11-25 19:59:33,008:INFO:SubProcess create_model() called ==================================
2024-11-25 19:59:33,008:INFO:Initializing create_model()
2024-11-25 19:59:33,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B316E1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 19:59:33,008:INFO:Checking exceptions
2024-11-25 19:59:33,008:INFO:Importing libraries
2024-11-25 19:59:33,008:INFO:Copying training dataset
2024-11-25 19:59:33,013:INFO:Defining folds
2024-11-25 19:59:33,014:INFO:Declaring metric variables
2024-11-25 19:59:33,014:INFO:Importing untrained model
2024-11-25 19:59:33,015:INFO:Gradient Boosting Classifier Imported successfully
2024-11-25 19:59:33,016:INFO:Starting cross validation
2024-11-25 19:59:33,017:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 19:59:33,020:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2024-11-25 19:59:33,718:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:33,723:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:33,726:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:33,727:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:33,728:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:33,729:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:33,729:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:33,730:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:33,733:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:33,734:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:33,735:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:33,738:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:33,740:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:33,742:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:33,745:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:33,746:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:33,750:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:33,793:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:33,796:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:33,800:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:33,803:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:33,805:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:34,414:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:34,417:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:34,419:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:34,421:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:34,424:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:34,426:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:34,528:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:34,530:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:34,532:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:34,535:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:34,537:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:34,540:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:34,591:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:34,594:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:34,596:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:34,599:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:34,603:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:34,605:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:34,632:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:34,634:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:34,637:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:34,639:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:34,640:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:34,643:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:34,645:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,191:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:35,193:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,195:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,197:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,199:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,202:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,205:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,206:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:35,208:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,210:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,211:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,213:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,216:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,218:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,223:INFO:Calculating mean and std
2024-11-25 19:59:35,224:INFO:Creating metrics dataframe
2024-11-25 19:59:35,226:INFO:Uploading results into container
2024-11-25 19:59:35,227:INFO:Uploading model into container now
2024-11-25 19:59:35,227:INFO:_master_model_container: 10
2024-11-25 19:59:35,227:INFO:_display_container: 2
2024-11-25 19:59:35,228:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-25 19:59:35,228:INFO:create_model() successfully completed......................................
2024-11-25 19:59:35,339:INFO:SubProcess create_model() end ==================================
2024-11-25 19:59:35,339:INFO:Creating metrics dataframe
2024-11-25 19:59:35,343:INFO:Initializing Linear Discriminant Analysis
2024-11-25 19:59:35,343:INFO:Total runtime is 0.2320937514305115 minutes
2024-11-25 19:59:35,343:INFO:SubProcess create_model() called ==================================
2024-11-25 19:59:35,344:INFO:Initializing create_model()
2024-11-25 19:59:35,344:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B316E1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 19:59:35,344:INFO:Checking exceptions
2024-11-25 19:59:35,344:INFO:Importing libraries
2024-11-25 19:59:35,344:INFO:Copying training dataset
2024-11-25 19:59:35,349:INFO:Defining folds
2024-11-25 19:59:35,349:INFO:Declaring metric variables
2024-11-25 19:59:35,349:INFO:Importing untrained model
2024-11-25 19:59:35,351:INFO:Linear Discriminant Analysis Imported successfully
2024-11-25 19:59:35,352:INFO:Starting cross validation
2024-11-25 19:59:35,353:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 19:59:35,357:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2024-11-25 19:59:35,475:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:35,477:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,478:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:35,478:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:35,480:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,480:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,482:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,484:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,486:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,486:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,487:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,487:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,489:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,490:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,492:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,492:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:35,504:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,508:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,511:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,513:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,515:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,517:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,599:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:35,599:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:35,604:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,604:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,606:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,606:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,607:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:35,608:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,608:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,609:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,610:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,611:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,612:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,612:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,612:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,616:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,618:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,626:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:35,630:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,632:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,634:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,636:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,638:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,714:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:35,716:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,717:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 19:59:35,718:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,719:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,720:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,720:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,723:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,724:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,726:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,727:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,728:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:35,730:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:35,735:INFO:Calculating mean and std
2024-11-25 19:59:35,737:INFO:Creating metrics dataframe
2024-11-25 19:59:35,739:INFO:Uploading results into container
2024-11-25 19:59:35,739:INFO:Uploading model into container now
2024-11-25 19:59:35,740:INFO:_master_model_container: 11
2024-11-25 19:59:35,740:INFO:_display_container: 2
2024-11-25 19:59:35,740:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-25 19:59:35,740:INFO:create_model() successfully completed......................................
2024-11-25 19:59:35,849:INFO:SubProcess create_model() end ==================================
2024-11-25 19:59:35,849:INFO:Creating metrics dataframe
2024-11-25 19:59:35,854:INFO:Initializing Extra Trees Classifier
2024-11-25 19:59:35,854:INFO:Total runtime is 0.24061799446741744 minutes
2024-11-25 19:59:35,855:INFO:SubProcess create_model() called ==================================
2024-11-25 19:59:35,855:INFO:Initializing create_model()
2024-11-25 19:59:35,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B316E1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 19:59:35,855:INFO:Checking exceptions
2024-11-25 19:59:35,856:INFO:Importing libraries
2024-11-25 19:59:35,856:INFO:Copying training dataset
2024-11-25 19:59:35,861:INFO:Defining folds
2024-11-25 19:59:35,861:INFO:Declaring metric variables
2024-11-25 19:59:35,861:INFO:Importing untrained model
2024-11-25 19:59:35,861:INFO:Extra Trees Classifier Imported successfully
2024-11-25 19:59:35,861:INFO:Starting cross validation
2024-11-25 19:59:35,861:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 19:59:35,861:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2024-11-25 19:59:36,178:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:36,178:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:36,181:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,181:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,185:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,187:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,187:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,190:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:36,191:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,192:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,193:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,194:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,197:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,199:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,209:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,238:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:36,240:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,244:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,247:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,249:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,251:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,253:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,491:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:36,496:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,496:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,501:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,503:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,506:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,520:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:36,523:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,525:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,527:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,529:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,531:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,553:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:36,555:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,557:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,559:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,561:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,564:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,594:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:36,597:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,598:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,601:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,606:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,608:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,801:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:36,804:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,806:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,808:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,809:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:36,810:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,811:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,812:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,813:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,814:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,816:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,819:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,821:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:36,823:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:36,828:INFO:Calculating mean and std
2024-11-25 19:59:36,829:INFO:Creating metrics dataframe
2024-11-25 19:59:36,831:INFO:Uploading results into container
2024-11-25 19:59:36,832:INFO:Uploading model into container now
2024-11-25 19:59:36,832:INFO:_master_model_container: 12
2024-11-25 19:59:36,832:INFO:_display_container: 2
2024-11-25 19:59:36,833:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-11-25 19:59:36,833:INFO:create_model() successfully completed......................................
2024-11-25 19:59:36,944:INFO:SubProcess create_model() end ==================================
2024-11-25 19:59:36,944:INFO:Creating metrics dataframe
2024-11-25 19:59:36,947:INFO:Initializing Light Gradient Boosting Machine
2024-11-25 19:59:36,947:INFO:Total runtime is 0.25882103840510057 minutes
2024-11-25 19:59:36,947:INFO:SubProcess create_model() called ==================================
2024-11-25 19:59:36,948:INFO:Initializing create_model()
2024-11-25 19:59:36,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B316E1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 19:59:36,948:INFO:Checking exceptions
2024-11-25 19:59:36,948:INFO:Importing libraries
2024-11-25 19:59:36,948:INFO:Copying training dataset
2024-11-25 19:59:36,953:INFO:Defining folds
2024-11-25 19:59:36,953:INFO:Declaring metric variables
2024-11-25 19:59:36,954:INFO:Importing untrained model
2024-11-25 19:59:36,954:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-25 19:59:36,955:INFO:Starting cross validation
2024-11-25 19:59:36,956:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 19:59:36,959:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2024-11-25 19:59:37,266:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:37,268:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,271:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:37,272:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:37,274:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,275:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,276:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,278:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,279:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,280:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:37,280:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,281:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,284:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,285:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,287:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,287:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,288:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,290:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,292:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,295:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,299:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,301:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,611:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:37,620:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,622:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,624:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,627:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,632:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:37,632:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,634:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:37,634:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,636:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,636:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,638:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,638:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,640:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,640:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,644:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

 f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,646:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,647:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,649:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,660:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:37,662:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,664:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,666:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,668:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,672:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,674:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,801:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:37,806:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,808:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,811:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,812:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,813:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:37,815:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,817:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,819:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,819:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,822:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,823:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,826:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:37,827:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:37,834:INFO:Calculating mean and std
2024-11-25 19:59:37,835:INFO:Creating metrics dataframe
2024-11-25 19:59:37,837:INFO:Uploading results into container
2024-11-25 19:59:37,838:INFO:Uploading model into container now
2024-11-25 19:59:37,838:INFO:_master_model_container: 13
2024-11-25 19:59:37,838:INFO:_display_container: 2
2024-11-25 19:59:37,839:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-25 19:59:37,839:INFO:create_model() successfully completed......................................
2024-11-25 19:59:37,951:INFO:SubProcess create_model() end ==================================
2024-11-25 19:59:37,951:INFO:Creating metrics dataframe
2024-11-25 19:59:37,955:INFO:Initializing Dummy Classifier
2024-11-25 19:59:37,955:INFO:Total runtime is 0.2756310423215231 minutes
2024-11-25 19:59:37,955:INFO:SubProcess create_model() called ==================================
2024-11-25 19:59:37,955:INFO:Initializing create_model()
2024-11-25 19:59:37,956:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B316E1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 19:59:37,956:INFO:Checking exceptions
2024-11-25 19:59:37,956:INFO:Importing libraries
2024-11-25 19:59:37,956:INFO:Copying training dataset
2024-11-25 19:59:37,960:INFO:Defining folds
2024-11-25 19:59:37,960:INFO:Declaring metric variables
2024-11-25 19:59:37,961:INFO:Importing untrained model
2024-11-25 19:59:37,961:INFO:Dummy Classifier Imported successfully
2024-11-25 19:59:37,962:INFO:Starting cross validation
2024-11-25 19:59:37,964:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 19:59:37,967:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2024-11-25 19:59:38,116:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:38,116:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:38,116:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,116:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:38,116:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,121:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,123:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,123:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,123:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,123:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,130:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,131:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,132:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,134:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,146:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:38,148:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,152:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,154:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,157:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,159:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,161:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,246:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:38,249:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,250:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,253:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,253:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:38,255:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:38,255:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,259:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,259:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,260:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,260:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,261:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,262:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,262:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,263:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,264:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,266:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,266:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,268:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,268:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,279:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:38,282:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,286:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,288:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,290:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,292:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,294:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,365:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:38,367:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,369:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,371:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,372:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 19:59:38,373:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,374:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,376:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,377:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,381:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,382:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,384:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,386:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Teacher') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 19:59:38,388:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 19:59:38,395:INFO:Calculating mean and std
2024-11-25 19:59:38,396:INFO:Creating metrics dataframe
2024-11-25 19:59:38,398:INFO:Uploading results into container
2024-11-25 19:59:38,399:INFO:Uploading model into container now
2024-11-25 19:59:38,399:INFO:_master_model_container: 14
2024-11-25 19:59:38,399:INFO:_display_container: 2
2024-11-25 19:59:38,400:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-11-25 19:59:38,400:INFO:create_model() successfully completed......................................
2024-11-25 19:59:38,517:INFO:SubProcess create_model() end ==================================
2024-11-25 19:59:38,517:INFO:Creating metrics dataframe
2024-11-25 19:59:38,524:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-11-25 19:59:38,526:INFO:Initializing create_model()
2024-11-25 19:59:38,526:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 19:59:38,526:INFO:Checking exceptions
2024-11-25 19:59:38,527:INFO:Importing libraries
2024-11-25 19:59:38,527:INFO:Copying training dataset
2024-11-25 19:59:38,531:INFO:Defining folds
2024-11-25 19:59:38,531:INFO:Declaring metric variables
2024-11-25 19:59:38,531:INFO:Importing untrained model
2024-11-25 19:59:38,532:INFO:Declaring custom model
2024-11-25 19:59:38,532:INFO:Logistic Regression Imported successfully
2024-11-25 19:59:38,534:INFO:Cross validation set to False
2024-11-25 19:59:38,534:INFO:Fitting Model
2024-11-25 19:59:38,808:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-25 19:59:38,809:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-25 19:59:38,809:INFO:create_model() successfully completed......................................
2024-11-25 19:59:38,925:INFO:Initializing create_model()
2024-11-25 19:59:38,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 19:59:38,925:INFO:Checking exceptions
2024-11-25 19:59:38,926:INFO:Importing libraries
2024-11-25 19:59:38,926:INFO:Copying training dataset
2024-11-25 19:59:38,930:INFO:Defining folds
2024-11-25 19:59:38,930:INFO:Declaring metric variables
2024-11-25 19:59:38,930:INFO:Importing untrained model
2024-11-25 19:59:38,930:INFO:Declaring custom model
2024-11-25 19:59:38,931:INFO:Naive Bayes Imported successfully
2024-11-25 19:59:38,932:INFO:Cross validation set to False
2024-11-25 19:59:38,932:INFO:Fitting Model
2024-11-25 19:59:38,992:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-25 19:59:38,992:INFO:create_model() successfully completed......................................
2024-11-25 19:59:39,103:INFO:Initializing create_model()
2024-11-25 19:59:39,103:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 19:59:39,103:INFO:Checking exceptions
2024-11-25 19:59:39,104:INFO:Importing libraries
2024-11-25 19:59:39,104:INFO:Copying training dataset
2024-11-25 19:59:39,108:INFO:Defining folds
2024-11-25 19:59:39,108:INFO:Declaring metric variables
2024-11-25 19:59:39,108:INFO:Importing untrained model
2024-11-25 19:59:39,108:INFO:Declaring custom model
2024-11-25 19:59:39,109:INFO:Ada Boost Classifier Imported successfully
2024-11-25 19:59:39,112:INFO:Cross validation set to False
2024-11-25 19:59:39,112:INFO:Fitting Model
2024-11-25 19:59:39,175:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 19:59:39,276:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-11-25 19:59:39,276:INFO:create_model() successfully completed......................................
2024-11-25 19:59:39,388:INFO:Initializing create_model()
2024-11-25 19:59:39,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 19:59:39,388:INFO:Checking exceptions
2024-11-25 19:59:39,389:INFO:Importing libraries
2024-11-25 19:59:39,389:INFO:Copying training dataset
2024-11-25 19:59:39,396:INFO:Defining folds
2024-11-25 19:59:39,396:INFO:Declaring metric variables
2024-11-25 19:59:39,396:INFO:Importing untrained model
2024-11-25 19:59:39,397:INFO:Declaring custom model
2024-11-25 19:59:39,397:INFO:Ridge Classifier Imported successfully
2024-11-25 19:59:39,399:INFO:Cross validation set to False
2024-11-25 19:59:39,399:INFO:Fitting Model
2024-11-25 19:59:39,461:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-25 19:59:39,461:INFO:create_model() successfully completed......................................
2024-11-25 19:59:39,578:INFO:Initializing create_model()
2024-11-25 19:59:39,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 19:59:39,578:INFO:Checking exceptions
2024-11-25 19:59:39,579:INFO:Importing libraries
2024-11-25 19:59:39,580:INFO:Copying training dataset
2024-11-25 19:59:39,584:INFO:Defining folds
2024-11-25 19:59:39,584:INFO:Declaring metric variables
2024-11-25 19:59:39,584:INFO:Importing untrained model
2024-11-25 19:59:39,584:INFO:Declaring custom model
2024-11-25 19:59:39,585:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-25 19:59:39,586:INFO:Cross validation set to False
2024-11-25 19:59:39,586:INFO:Fitting Model
2024-11-25 19:59:39,649:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-25 19:59:39,650:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-25 19:59:39,650:INFO:create_model() successfully completed......................................
2024-11-25 19:59:39,783:INFO:_master_model_container: 14
2024-11-25 19:59:39,783:INFO:_display_container: 2
2024-11-25 19:59:39,784:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)]
2024-11-25 19:59:39,784:INFO:compare_models() successfully completed......................................
2024-11-25 20:00:24,788:INFO:Initializing predict_model()
2024-11-25 20:00:24,788:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B280B790>, estimator=LogisticRegression(max_iter=1000, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D0B323D9E0>)
2024-11-25 20:00:24,789:INFO:Checking exceptions
2024-11-25 20:00:24,789:INFO:Preloading libraries
2024-11-25 20:00:24,789:INFO:Set up data.
2024-11-25 20:00:24,793:INFO:Set up index.
2024-11-25 20:00:34,750:INFO:PyCaret ClassificationExperiment
2024-11-25 20:00:34,750:INFO:Logging name: clf-default-name
2024-11-25 20:00:34,751:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-25 20:00:34,751:INFO:version 3.3.1
2024-11-25 20:00:34,751:INFO:Initializing setup()
2024-11-25 20:00:34,751:INFO:self.USI: 2c26
2024-11-25 20:00:34,752:INFO:self._variable_keys: {'idx', 'exp_name_log', '_available_plots', 'USI', 'target_param', 'fold_generator', 'X_train', 'fold_shuffle_param', '_ml_usecase', 'is_multiclass', 'gpu_n_jobs_param', 'fold_groups_param', 'logging_param', 'seed', 'exp_id', 'X_test', 'pipeline', 'data', 'n_jobs_param', 'fix_imbalance', 'html_param', 'X', 'y_test', 'memory', 'y_train', 'log_plots_param', 'gpu_param', 'y'}
2024-11-25 20:00:34,752:INFO:Checking environment
2024-11-25 20:00:34,752:INFO:python_version: 3.11.9
2024-11-25 20:00:34,752:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-11-25 20:00:34,752:INFO:machine: AMD64
2024-11-25 20:00:34,752:INFO:platform: Windows-10-10.0.19045-SP0
2024-11-25 20:00:34,753:INFO:Memory: svmem(total=17107767296, available=7540686848, percent=55.9, used=9567080448, free=7540686848)
2024-11-25 20:00:34,753:INFO:Physical Core: 4
2024-11-25 20:00:34,753:INFO:Logical Core: 4
2024-11-25 20:00:34,753:INFO:Checking libraries
2024-11-25 20:00:34,753:INFO:System:
2024-11-25 20:00:34,754:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-11-25 20:00:34,754:INFO:executable: C:\Users\krzys\.conda\envs\datascience\python.exe
2024-11-25 20:00:34,754:INFO:   machine: Windows-10-10.0.19045-SP0
2024-11-25 20:00:34,754:INFO:PyCaret required dependencies:
2024-11-25 20:00:34,754:INFO:                 pip: 24.0
2024-11-25 20:00:34,754:INFO:          setuptools: 69.5.1
2024-11-25 20:00:34,754:INFO:             pycaret: 3.3.2
2024-11-25 20:00:34,755:INFO:             IPython: 8.25.0
2024-11-25 20:00:34,755:INFO:          ipywidgets: 7.8.1
2024-11-25 20:00:34,756:INFO:                tqdm: 4.66.5
2024-11-25 20:00:34,757:INFO:               numpy: 1.26.4
2024-11-25 20:00:34,757:INFO:              pandas: 1.5.3
2024-11-25 20:00:34,758:INFO:              jinja2: 3.1.4
2024-11-25 20:00:34,758:INFO:               scipy: 1.11.4
2024-11-25 20:00:34,758:INFO:              joblib: 1.3.2
2024-11-25 20:00:34,758:INFO:             sklearn: 1.4.2
2024-11-25 20:00:34,758:INFO:                pyod: 2.0.2
2024-11-25 20:00:34,759:INFO:            imblearn: 0.12.4
2024-11-25 20:00:34,759:INFO:   category_encoders: 2.6.4
2024-11-25 20:00:34,759:INFO:            lightgbm: 4.5.0
2024-11-25 20:00:34,759:INFO:               numba: 0.60.0
2024-11-25 20:00:34,759:INFO:            requests: 2.32.3
2024-11-25 20:00:34,759:INFO:          matplotlib: 3.8.4
2024-11-25 20:00:34,759:INFO:          scikitplot: 0.3.7
2024-11-25 20:00:34,759:INFO:         yellowbrick: 1.5
2024-11-25 20:00:34,760:INFO:              plotly: 5.22.0
2024-11-25 20:00:34,760:INFO:    plotly-resampler: Not installed
2024-11-25 20:00:34,760:INFO:             kaleido: 0.2.1
2024-11-25 20:00:34,760:INFO:           schemdraw: 0.15
2024-11-25 20:00:34,760:INFO:         statsmodels: 0.14.4
2024-11-25 20:00:34,760:INFO:              sktime: 0.26.0
2024-11-25 20:00:34,760:INFO:               tbats: 1.1.3
2024-11-25 20:00:34,764:INFO:            pmdarima: 2.0.4
2024-11-25 20:00:34,765:INFO:              psutil: 5.9.0
2024-11-25 20:00:34,765:INFO:          markupsafe: 2.1.3
2024-11-25 20:00:34,766:INFO:             pickle5: Not installed
2024-11-25 20:00:34,766:INFO:         cloudpickle: 3.0.0
2024-11-25 20:00:34,766:INFO:         deprecation: 2.1.0
2024-11-25 20:00:34,766:INFO:              xxhash: 3.5.0
2024-11-25 20:00:34,766:INFO:           wurlitzer: 3.1.1
2024-11-25 20:00:34,766:INFO:PyCaret optional dependencies:
2024-11-25 20:00:34,766:INFO:                shap: Not installed
2024-11-25 20:00:34,767:INFO:           interpret: Not installed
2024-11-25 20:00:34,767:INFO:                umap: Not installed
2024-11-25 20:00:34,767:INFO:     ydata_profiling: 0.0.dev0
2024-11-25 20:00:34,767:INFO:  explainerdashboard: Not installed
2024-11-25 20:00:34,767:INFO:             autoviz: Not installed
2024-11-25 20:00:34,767:INFO:           fairlearn: Not installed
2024-11-25 20:00:34,767:INFO:          deepchecks: Not installed
2024-11-25 20:00:34,767:INFO:             xgboost: Not installed
2024-11-25 20:00:34,768:INFO:            catboost: Not installed
2024-11-25 20:00:34,768:INFO:              kmodes: Not installed
2024-11-25 20:00:34,768:INFO:             mlxtend: Not installed
2024-11-25 20:00:34,768:INFO:       statsforecast: Not installed
2024-11-25 20:00:34,768:INFO:        tune_sklearn: Not installed
2024-11-25 20:00:34,768:INFO:                 ray: Not installed
2024-11-25 20:00:34,768:INFO:            hyperopt: Not installed
2024-11-25 20:00:34,769:INFO:              optuna: Not installed
2024-11-25 20:00:34,769:INFO:               skopt: Not installed
2024-11-25 20:00:34,769:INFO:              mlflow: Not installed
2024-11-25 20:00:34,769:INFO:              gradio: Not installed
2024-11-25 20:00:34,769:INFO:             fastapi: Not installed
2024-11-25 20:00:34,770:INFO:             uvicorn: Not installed
2024-11-25 20:00:34,770:INFO:              m2cgen: Not installed
2024-11-25 20:00:34,770:INFO:           evidently: Not installed
2024-11-25 20:00:34,770:INFO:               fugue: Not installed
2024-11-25 20:00:34,770:INFO:           streamlit: 1.37.1
2024-11-25 20:00:34,770:INFO:             prophet: Not installed
2024-11-25 20:00:34,770:INFO:None
2024-11-25 20:00:34,771:INFO:Set up data.
2024-11-25 20:00:34,778:INFO:Set up folding strategy.
2024-11-25 20:00:34,778:INFO:Set up train/test split.
2024-11-25 20:00:34,783:INFO:Set up index.
2024-11-25 20:00:34,784:INFO:Assigning column types.
2024-11-25 20:00:34,791:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-25 20:00:34,875:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-25 20:00:34,877:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-25 20:00:34,926:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 20:00:34,926:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 20:00:35,005:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-25 20:00:35,006:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-25 20:00:35,056:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 20:00:35,056:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 20:00:35,057:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-25 20:00:35,135:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-25 20:00:35,182:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 20:00:35,182:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 20:00:35,262:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-25 20:00:35,309:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 20:00:35,310:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 20:00:35,311:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-25 20:00:35,442:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 20:00:35,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 20:00:35,577:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 20:00:35,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 20:00:35,580:INFO:Preparing preprocessing pipeline...
2024-11-25 20:00:35,581:INFO:Set up label encoding.
2024-11-25 20:00:35,581:INFO:Set up simple imputation.
2024-11-25 20:00:35,611:INFO:Finished creating preprocessing pipeline.
2024-11-25 20:00:35,619:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\krzys\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal_length', 'sepal_width',
                                             'petal_length', 'petal_width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-11-25 20:00:35,619:INFO:Creating final display dataframe.
2024-11-25 20:00:35,706:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                123
1                        Target                                            species
2                   Target type                                         Multiclass
3                Target mapping  Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...
4           Original data shape                                           (150, 5)
5        Transformed data shape                                           (150, 5)
6   Transformed train set shape                                           (105, 5)
7    Transformed test set shape                                            (45, 5)
8              Numeric features                                                  4
9                    Preprocess                                               True
10              Imputation type                                             simple
11           Numeric imputation                                               mean
12       Categorical imputation                                               mode
13               Fold Generator                                    StratifiedKFold
14                  Fold Number                                                 10
15                     CPU Jobs                                                 -1
16                      Use GPU                                              False
17               Log Experiment                                              False
18              Experiment Name                                   clf-default-name
19                          USI                                               2c26
2024-11-25 20:00:35,856:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 20:00:35,856:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 20:00:35,994:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 20:00:35,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-25 20:00:35,996:INFO:setup() successfully completed in 1.25s...............
2024-11-25 20:00:35,996:INFO:Initializing compare_models()
2024-11-25 20:00:35,996:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-11-25 20:00:35,996:INFO:Checking exceptions
2024-11-25 20:00:35,999:INFO:Preparing display monitor
2024-11-25 20:00:36,003:INFO:Initializing Logistic Regression
2024-11-25 20:00:36,003:INFO:Total runtime is 0.0 minutes
2024-11-25 20:00:36,003:INFO:SubProcess create_model() called ==================================
2024-11-25 20:00:36,004:INFO:Initializing create_model()
2024-11-25 20:00:36,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B2EA7D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 20:00:36,004:INFO:Checking exceptions
2024-11-25 20:00:36,004:INFO:Importing libraries
2024-11-25 20:00:36,004:INFO:Copying training dataset
2024-11-25 20:00:36,008:INFO:Defining folds
2024-11-25 20:00:36,008:INFO:Declaring metric variables
2024-11-25 20:00:36,008:INFO:Importing untrained model
2024-11-25 20:00:36,009:INFO:Logistic Regression Imported successfully
2024-11-25 20:00:36,010:INFO:Starting cross validation
2024-11-25 20:00:36,011:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 20:00:36,072:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:36,074:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,074:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,075:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:36,077:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,078:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,081:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,085:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,087:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

 a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:36,088:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,089:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,090:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,092:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,104:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,140:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:36,141:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:36,142:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,143:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,146:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,147:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,149:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:36,151:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,152:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,153:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,156:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,164:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,166:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:36,168:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,172:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,177:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,209:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:36,209:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:36,211:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,211:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,215:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,215:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,219:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,219:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,228:INFO:Calculating mean and std
2024-11-25 20:00:36,229:INFO:Creating metrics dataframe
2024-11-25 20:00:36,231:INFO:Uploading results into container
2024-11-25 20:00:36,232:INFO:Uploading model into container now
2024-11-25 20:00:36,232:INFO:_master_model_container: 1
2024-11-25 20:00:36,232:INFO:_display_container: 2
2024-11-25 20:00:36,233:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-25 20:00:36,233:INFO:create_model() successfully completed......................................
2024-11-25 20:00:36,346:INFO:SubProcess create_model() end ==================================
2024-11-25 20:00:36,347:INFO:Creating metrics dataframe
2024-11-25 20:00:36,351:INFO:Initializing K Neighbors Classifier
2024-11-25 20:00:36,352:INFO:Total runtime is 0.005813384056091308 minutes
2024-11-25 20:00:36,352:INFO:SubProcess create_model() called ==================================
2024-11-25 20:00:36,353:INFO:Initializing create_model()
2024-11-25 20:00:36,353:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B2EA7D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 20:00:36,353:INFO:Checking exceptions
2024-11-25 20:00:36,355:INFO:Importing libraries
2024-11-25 20:00:36,355:INFO:Copying training dataset
2024-11-25 20:00:36,360:INFO:Defining folds
2024-11-25 20:00:36,360:INFO:Declaring metric variables
2024-11-25 20:00:36,360:INFO:Importing untrained model
2024-11-25 20:00:36,362:INFO:K Neighbors Classifier Imported successfully
2024-11-25 20:00:36,364:INFO:Starting cross validation
2024-11-25 20:00:36,365:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 20:00:36,426:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,427:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,429:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,430:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,433:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,434:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,434:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,436:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,437:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,438:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,438:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,440:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,446:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,450:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,452:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,458:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,477:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,477:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,479:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,484:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,486:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,488:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,490:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,504:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,507:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,512:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,514:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,516:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,516:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,520:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,526:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,531:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,533:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,538:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,540:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,542:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,542:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,545:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,550:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,557:INFO:Calculating mean and std
2024-11-25 20:00:36,558:INFO:Creating metrics dataframe
2024-11-25 20:00:36,560:INFO:Uploading results into container
2024-11-25 20:00:36,561:INFO:Uploading model into container now
2024-11-25 20:00:36,561:INFO:_master_model_container: 2
2024-11-25 20:00:36,561:INFO:_display_container: 2
2024-11-25 20:00:36,562:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-25 20:00:36,562:INFO:create_model() successfully completed......................................
2024-11-25 20:00:36,670:INFO:SubProcess create_model() end ==================================
2024-11-25 20:00:36,670:INFO:Creating metrics dataframe
2024-11-25 20:00:36,673:INFO:Initializing Naive Bayes
2024-11-25 20:00:36,673:INFO:Total runtime is 0.01117632786432902 minutes
2024-11-25 20:00:36,674:INFO:SubProcess create_model() called ==================================
2024-11-25 20:00:36,675:INFO:Initializing create_model()
2024-11-25 20:00:36,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B2EA7D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 20:00:36,675:INFO:Checking exceptions
2024-11-25 20:00:36,675:INFO:Importing libraries
2024-11-25 20:00:36,675:INFO:Copying training dataset
2024-11-25 20:00:36,680:INFO:Defining folds
2024-11-25 20:00:36,680:INFO:Declaring metric variables
2024-11-25 20:00:36,680:INFO:Importing untrained model
2024-11-25 20:00:36,681:INFO:Naive Bayes Imported successfully
2024-11-25 20:00:36,682:INFO:Starting cross validation
2024-11-25 20:00:36,683:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 20:00:36,717:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,718:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,719:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,720:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,724:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,725:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,729:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,729:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,729:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,731:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,736:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,739:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,740:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,744:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,745:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,760:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,761:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,765:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,770:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,776:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,779:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,780:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,783:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,785:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,785:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,791:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,791:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,795:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,796:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,798:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,804:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,807:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,817:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,819:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,820:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:36,823:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,823:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,826:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,827:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,832:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:36,838:INFO:Calculating mean and std
2024-11-25 20:00:36,839:INFO:Creating metrics dataframe
2024-11-25 20:00:36,842:INFO:Uploading results into container
2024-11-25 20:00:36,843:INFO:Uploading model into container now
2024-11-25 20:00:36,843:INFO:_master_model_container: 3
2024-11-25 20:00:36,844:INFO:_display_container: 2
2024-11-25 20:00:36,844:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-25 20:00:36,844:INFO:create_model() successfully completed......................................
2024-11-25 20:00:36,954:INFO:SubProcess create_model() end ==================================
2024-11-25 20:00:36,955:INFO:Creating metrics dataframe
2024-11-25 20:00:36,958:INFO:Initializing Decision Tree Classifier
2024-11-25 20:00:36,958:INFO:Total runtime is 0.015928995609283448 minutes
2024-11-25 20:00:36,959:INFO:SubProcess create_model() called ==================================
2024-11-25 20:00:36,959:INFO:Initializing create_model()
2024-11-25 20:00:36,959:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B2EA7D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 20:00:36,959:INFO:Checking exceptions
2024-11-25 20:00:36,959:INFO:Importing libraries
2024-11-25 20:00:36,959:INFO:Copying training dataset
2024-11-25 20:00:36,965:INFO:Defining folds
2024-11-25 20:00:36,965:INFO:Declaring metric variables
2024-11-25 20:00:36,965:INFO:Importing untrained model
2024-11-25 20:00:36,966:INFO:Decision Tree Classifier Imported successfully
2024-11-25 20:00:36,966:INFO:Starting cross validation
2024-11-25 20:00:36,967:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 20:00:37,004:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:37,006:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,009:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:37,010:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,011:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,011:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:37,013:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,015:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,019:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,019:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

 a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:37,020:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,021:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,022:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,025:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,037:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,051:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:37,052:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:37,053:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:37,055:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,056:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,059:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,061:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,064:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,065:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,070:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,075:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,079:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,082:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:37,091:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,091:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:37,096:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,096:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,101:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,105:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:37,105:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,106:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,107:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,113:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,117:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,124:INFO:Calculating mean and std
2024-11-25 20:00:37,126:INFO:Creating metrics dataframe
2024-11-25 20:00:37,128:INFO:Uploading results into container
2024-11-25 20:00:37,129:INFO:Uploading model into container now
2024-11-25 20:00:37,129:INFO:_master_model_container: 4
2024-11-25 20:00:37,129:INFO:_display_container: 2
2024-11-25 20:00:37,129:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-11-25 20:00:37,130:INFO:create_model() successfully completed......................................
2024-11-25 20:00:37,248:INFO:SubProcess create_model() end ==================================
2024-11-25 20:00:37,248:INFO:Creating metrics dataframe
2024-11-25 20:00:37,251:INFO:Initializing SVM - Linear Kernel
2024-11-25 20:00:37,251:INFO:Total runtime is 0.02080841064453125 minutes
2024-11-25 20:00:37,252:INFO:SubProcess create_model() called ==================================
2024-11-25 20:00:37,252:INFO:Initializing create_model()
2024-11-25 20:00:37,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B2EA7D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 20:00:37,252:INFO:Checking exceptions
2024-11-25 20:00:37,252:INFO:Importing libraries
2024-11-25 20:00:37,252:INFO:Copying training dataset
2024-11-25 20:00:37,257:INFO:Defining folds
2024-11-25 20:00:37,257:INFO:Declaring metric variables
2024-11-25 20:00:37,258:INFO:Importing untrained model
2024-11-25 20:00:37,258:INFO:SVM - Linear Kernel Imported successfully
2024-11-25 20:00:37,259:INFO:Starting cross validation
2024-11-25 20:00:37,260:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 20:00:37,317:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,319:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,319:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,319:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,321:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,322:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,326:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,327:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,328:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,328:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 20:00:37,328:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 20:00:37,331:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,332:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,333:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,358:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,360:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,366:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,368:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 20:00:37,370:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,385:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,387:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,389:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,390:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,391:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,392:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,393:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,395:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,397:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,397:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,404:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,405:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,411:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,415:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,419:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,421:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 20:00:37,424:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,437:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,439:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,443:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,445:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 20:00:37,446:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,448:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,448:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,452:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,455:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 20:00:37,458:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,464:INFO:Calculating mean and std
2024-11-25 20:00:37,466:INFO:Creating metrics dataframe
2024-11-25 20:00:37,468:INFO:Uploading results into container
2024-11-25 20:00:37,468:INFO:Uploading model into container now
2024-11-25 20:00:37,469:INFO:_master_model_container: 5
2024-11-25 20:00:37,469:INFO:_display_container: 2
2024-11-25 20:00:37,470:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-25 20:00:37,470:INFO:create_model() successfully completed......................................
2024-11-25 20:00:37,583:INFO:SubProcess create_model() end ==================================
2024-11-25 20:00:37,583:INFO:Creating metrics dataframe
2024-11-25 20:00:37,586:INFO:Initializing Ridge Classifier
2024-11-25 20:00:37,586:INFO:Total runtime is 0.02639363209406535 minutes
2024-11-25 20:00:37,586:INFO:SubProcess create_model() called ==================================
2024-11-25 20:00:37,587:INFO:Initializing create_model()
2024-11-25 20:00:37,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B2EA7D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 20:00:37,587:INFO:Checking exceptions
2024-11-25 20:00:37,587:INFO:Importing libraries
2024-11-25 20:00:37,587:INFO:Copying training dataset
2024-11-25 20:00:37,593:INFO:Defining folds
2024-11-25 20:00:37,593:INFO:Declaring metric variables
2024-11-25 20:00:37,594:INFO:Importing untrained model
2024-11-25 20:00:37,594:INFO:Ridge Classifier Imported successfully
2024-11-25 20:00:37,595:INFO:Starting cross validation
2024-11-25 20:00:37,596:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 20:00:37,642:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,644:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,645:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,645:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,646:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,648:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,649:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,650:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,652:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,654:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,654:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,655:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,657:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,658:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,673:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,677:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,692:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,693:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,693:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,694:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,696:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,696:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,698:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,700:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,701:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,702:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,704:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,705:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,715:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,718:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,723:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,727:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,737:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,740:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,741:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:37,743:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,743:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,747:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,747:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,752:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:37,758:INFO:Calculating mean and std
2024-11-25 20:00:37,759:INFO:Creating metrics dataframe
2024-11-25 20:00:37,763:INFO:Uploading results into container
2024-11-25 20:00:37,764:INFO:Uploading model into container now
2024-11-25 20:00:37,764:INFO:_master_model_container: 6
2024-11-25 20:00:37,764:INFO:_display_container: 2
2024-11-25 20:00:37,765:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-25 20:00:37,765:INFO:create_model() successfully completed......................................
2024-11-25 20:00:37,878:INFO:SubProcess create_model() end ==================================
2024-11-25 20:00:37,878:INFO:Creating metrics dataframe
2024-11-25 20:00:37,882:INFO:Initializing Random Forest Classifier
2024-11-25 20:00:37,882:INFO:Total runtime is 0.03132147789001465 minutes
2024-11-25 20:00:37,883:INFO:SubProcess create_model() called ==================================
2024-11-25 20:00:37,883:INFO:Initializing create_model()
2024-11-25 20:00:37,883:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B2EA7D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 20:00:37,883:INFO:Checking exceptions
2024-11-25 20:00:37,883:INFO:Importing libraries
2024-11-25 20:00:37,884:INFO:Copying training dataset
2024-11-25 20:00:37,887:INFO:Defining folds
2024-11-25 20:00:37,888:INFO:Declaring metric variables
2024-11-25 20:00:37,888:INFO:Importing untrained model
2024-11-25 20:00:37,889:INFO:Random Forest Classifier Imported successfully
2024-11-25 20:00:37,889:INFO:Starting cross validation
2024-11-25 20:00:37,890:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 20:00:38,192:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:38,192:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:38,196:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,197:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,200:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,201:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,205:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,206:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,211:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:38,221:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,231:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,233:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:38,236:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,236:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,239:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,246:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,488:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:38,490:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,494:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,500:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,502:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:38,505:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,510:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,514:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,534:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:38,536:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:38,537:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,539:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,541:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,543:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,544:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,547:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,780:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:38,782:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,784:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:38,786:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,786:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,791:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,792:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,795:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,803:INFO:Calculating mean and std
2024-11-25 20:00:38,805:INFO:Creating metrics dataframe
2024-11-25 20:00:38,807:INFO:Uploading results into container
2024-11-25 20:00:38,808:INFO:Uploading model into container now
2024-11-25 20:00:38,808:INFO:_master_model_container: 7
2024-11-25 20:00:38,808:INFO:_display_container: 2
2024-11-25 20:00:38,809:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-11-25 20:00:38,809:INFO:create_model() successfully completed......................................
2024-11-25 20:00:38,921:INFO:SubProcess create_model() end ==================================
2024-11-25 20:00:38,922:INFO:Creating metrics dataframe
2024-11-25 20:00:38,926:INFO:Initializing Quadratic Discriminant Analysis
2024-11-25 20:00:38,926:INFO:Total runtime is 0.048725314935048426 minutes
2024-11-25 20:00:38,926:INFO:SubProcess create_model() called ==================================
2024-11-25 20:00:38,927:INFO:Initializing create_model()
2024-11-25 20:00:38,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B2EA7D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 20:00:38,927:INFO:Checking exceptions
2024-11-25 20:00:38,927:INFO:Importing libraries
2024-11-25 20:00:38,927:INFO:Copying training dataset
2024-11-25 20:00:38,931:INFO:Defining folds
2024-11-25 20:00:38,931:INFO:Declaring metric variables
2024-11-25 20:00:38,931:INFO:Importing untrained model
2024-11-25 20:00:38,932:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-25 20:00:38,932:INFO:Starting cross validation
2024-11-25 20:00:38,933:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 20:00:38,973:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:38,974:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:38,975:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,976:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:38,978:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,978:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,980:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,982:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,982:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,986:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,986:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,987:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,988:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:38,991:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:38,995:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,009:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,020:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:39,022:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,022:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:39,024:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:39,026:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,026:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,026:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,031:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,033:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,036:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,036:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,047:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:39,049:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,053:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,058:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,064:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:39,065:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:39,067:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,067:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,071:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,073:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,075:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,077:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,085:INFO:Calculating mean and std
2024-11-25 20:00:39,085:INFO:Creating metrics dataframe
2024-11-25 20:00:39,085:INFO:Uploading results into container
2024-11-25 20:00:39,085:INFO:Uploading model into container now
2024-11-25 20:00:39,085:INFO:_master_model_container: 8
2024-11-25 20:00:39,085:INFO:_display_container: 2
2024-11-25 20:00:39,085:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-25 20:00:39,085:INFO:create_model() successfully completed......................................
2024-11-25 20:00:39,207:INFO:SubProcess create_model() end ==================================
2024-11-25 20:00:39,207:INFO:Creating metrics dataframe
2024-11-25 20:00:39,210:INFO:Initializing Ada Boost Classifier
2024-11-25 20:00:39,211:INFO:Total runtime is 0.053465803464253746 minutes
2024-11-25 20:00:39,211:INFO:SubProcess create_model() called ==================================
2024-11-25 20:00:39,211:INFO:Initializing create_model()
2024-11-25 20:00:39,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B2EA7D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 20:00:39,211:INFO:Checking exceptions
2024-11-25 20:00:39,211:INFO:Importing libraries
2024-11-25 20:00:39,211:INFO:Copying training dataset
2024-11-25 20:00:39,215:INFO:Defining folds
2024-11-25 20:00:39,216:INFO:Declaring metric variables
2024-11-25 20:00:39,217:INFO:Importing untrained model
2024-11-25 20:00:39,218:INFO:Ada Boost Classifier Imported successfully
2024-11-25 20:00:39,218:INFO:Starting cross validation
2024-11-25 20:00:39,219:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 20:00:39,247:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 20:00:39,249:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 20:00:39,249:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 20:00:39,259:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 20:00:39,401:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:39,403:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:39,405:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:39,406:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,407:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,407:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,410:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,411:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,411:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,413:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,414:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,414:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,424:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:39,426:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,433:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,436:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 20:00:39,438:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,438:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 20:00:39,439:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 20:00:39,460:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 20:00:39,584:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:39,586:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,587:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:39,590:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,591:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,594:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,595:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,596:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:39,598:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,598:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,603:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,608:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,617:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 20:00:39,621:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-25 20:00:39,623:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:39,625:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,630:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,635:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,757:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:39,759:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,760:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:39,762:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,764:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,767:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,768:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,770:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:39,780:INFO:Calculating mean and std
2024-11-25 20:00:39,781:INFO:Creating metrics dataframe
2024-11-25 20:00:39,783:INFO:Uploading results into container
2024-11-25 20:00:39,784:INFO:Uploading model into container now
2024-11-25 20:00:39,784:INFO:_master_model_container: 9
2024-11-25 20:00:39,785:INFO:_display_container: 2
2024-11-25 20:00:39,785:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-11-25 20:00:39,785:INFO:create_model() successfully completed......................................
2024-11-25 20:00:39,900:INFO:SubProcess create_model() end ==================================
2024-11-25 20:00:39,900:INFO:Creating metrics dataframe
2024-11-25 20:00:39,904:INFO:Initializing Gradient Boosting Classifier
2024-11-25 20:00:39,904:INFO:Total runtime is 0.0650200088818868 minutes
2024-11-25 20:00:39,904:INFO:SubProcess create_model() called ==================================
2024-11-25 20:00:39,904:INFO:Initializing create_model()
2024-11-25 20:00:39,904:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B2EA7D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 20:00:39,904:INFO:Checking exceptions
2024-11-25 20:00:39,905:INFO:Importing libraries
2024-11-25 20:00:39,905:INFO:Copying training dataset
2024-11-25 20:00:39,909:INFO:Defining folds
2024-11-25 20:00:39,909:INFO:Declaring metric variables
2024-11-25 20:00:39,910:INFO:Importing untrained model
2024-11-25 20:00:39,911:INFO:Gradient Boosting Classifier Imported successfully
2024-11-25 20:00:39,912:INFO:Starting cross validation
2024-11-25 20:00:39,913:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 20:00:40,392:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:40,394:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,398:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,401:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,410:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:40,412:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,417:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:40,418:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,419:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,423:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,423:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,425:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:40,427:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,427:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,431:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,436:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,879:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:40,881:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,889:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,893:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,911:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:40,915:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,917:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,925:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:40,926:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,927:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:40,927:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,929:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,931:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,934:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,935:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:40,940:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,366:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:41,372:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,376:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,380:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,385:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:41,389:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,394:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,398:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,406:INFO:Calculating mean and std
2024-11-25 20:00:41,407:INFO:Creating metrics dataframe
2024-11-25 20:00:41,409:INFO:Uploading results into container
2024-11-25 20:00:41,410:INFO:Uploading model into container now
2024-11-25 20:00:41,410:INFO:_master_model_container: 10
2024-11-25 20:00:41,411:INFO:_display_container: 2
2024-11-25 20:00:41,411:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-25 20:00:41,411:INFO:create_model() successfully completed......................................
2024-11-25 20:00:41,525:INFO:SubProcess create_model() end ==================================
2024-11-25 20:00:41,525:INFO:Creating metrics dataframe
2024-11-25 20:00:41,528:INFO:Initializing Linear Discriminant Analysis
2024-11-25 20:00:41,529:INFO:Total runtime is 0.09211287498474122 minutes
2024-11-25 20:00:41,529:INFO:SubProcess create_model() called ==================================
2024-11-25 20:00:41,529:INFO:Initializing create_model()
2024-11-25 20:00:41,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B2EA7D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 20:00:41,530:INFO:Checking exceptions
2024-11-25 20:00:41,530:INFO:Importing libraries
2024-11-25 20:00:41,530:INFO:Copying training dataset
2024-11-25 20:00:41,534:INFO:Defining folds
2024-11-25 20:00:41,534:INFO:Declaring metric variables
2024-11-25 20:00:41,534:INFO:Importing untrained model
2024-11-25 20:00:41,535:INFO:Linear Discriminant Analysis Imported successfully
2024-11-25 20:00:41,535:INFO:Starting cross validation
2024-11-25 20:00:41,535:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 20:00:41,583:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:41,583:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:41,584:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:41,585:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,585:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,586:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,589:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,590:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,593:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:41,595:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,595:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,596:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,597:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,599:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,606:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,627:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:41,627:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:41,629:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,634:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,634:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,638:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,639:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,640:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:41,643:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,648:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:41,649:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,652:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,654:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,655:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,661:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,669:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:41,669:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-25 20:00:41,672:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,672:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,676:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,676:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,680:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,680:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:41,689:INFO:Calculating mean and std
2024-11-25 20:00:41,690:INFO:Creating metrics dataframe
2024-11-25 20:00:41,692:INFO:Uploading results into container
2024-11-25 20:00:41,693:INFO:Uploading model into container now
2024-11-25 20:00:41,693:INFO:_master_model_container: 11
2024-11-25 20:00:41,693:INFO:_display_container: 2
2024-11-25 20:00:41,693:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-25 20:00:41,694:INFO:create_model() successfully completed......................................
2024-11-25 20:00:41,810:INFO:SubProcess create_model() end ==================================
2024-11-25 20:00:41,811:INFO:Creating metrics dataframe
2024-11-25 20:00:41,814:INFO:Initializing Extra Trees Classifier
2024-11-25 20:00:41,814:INFO:Total runtime is 0.09685832262039185 minutes
2024-11-25 20:00:41,814:INFO:SubProcess create_model() called ==================================
2024-11-25 20:00:41,815:INFO:Initializing create_model()
2024-11-25 20:00:41,815:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B2EA7D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 20:00:41,815:INFO:Checking exceptions
2024-11-25 20:00:41,815:INFO:Importing libraries
2024-11-25 20:00:41,815:INFO:Copying training dataset
2024-11-25 20:00:41,820:INFO:Defining folds
2024-11-25 20:00:41,820:INFO:Declaring metric variables
2024-11-25 20:00:41,821:INFO:Importing untrained model
2024-11-25 20:00:41,822:INFO:Extra Trees Classifier Imported successfully
2024-11-25 20:00:41,822:INFO:Starting cross validation
2024-11-25 20:00:41,823:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 20:00:42,049:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:42,050:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:42,051:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,052:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,056:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,056:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,061:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:42,062:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,064:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,068:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,073:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,099:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:42,101:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,105:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,113:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,299:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:42,301:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,302:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,305:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,306:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,309:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,315:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,322:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:42,326:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,330:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,335:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,428:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:42,432:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,436:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,440:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,542:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:42,542:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:42,544:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,544:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,548:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,549:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,553:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,555:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:42,561:INFO:Calculating mean and std
2024-11-25 20:00:42,561:INFO:Creating metrics dataframe
2024-11-25 20:00:42,561:INFO:Uploading results into container
2024-11-25 20:00:42,561:INFO:Uploading model into container now
2024-11-25 20:00:42,561:INFO:_master_model_container: 12
2024-11-25 20:00:42,561:INFO:_display_container: 2
2024-11-25 20:00:42,561:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-11-25 20:00:42,561:INFO:create_model() successfully completed......................................
2024-11-25 20:00:42,681:INFO:SubProcess create_model() end ==================================
2024-11-25 20:00:42,681:INFO:Creating metrics dataframe
2024-11-25 20:00:42,687:INFO:Initializing Light Gradient Boosting Machine
2024-11-25 20:00:42,687:INFO:Total runtime is 0.11139968633651734 minutes
2024-11-25 20:00:42,687:INFO:SubProcess create_model() called ==================================
2024-11-25 20:00:42,688:INFO:Initializing create_model()
2024-11-25 20:00:42,688:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B2EA7D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 20:00:42,688:INFO:Checking exceptions
2024-11-25 20:00:42,688:INFO:Importing libraries
2024-11-25 20:00:42,688:INFO:Copying training dataset
2024-11-25 20:00:42,692:INFO:Defining folds
2024-11-25 20:00:42,692:INFO:Declaring metric variables
2024-11-25 20:00:42,693:INFO:Importing untrained model
2024-11-25 20:00:42,693:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-25 20:00:42,694:INFO:Starting cross validation
2024-11-25 20:00:42,695:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 20:00:43,173:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:43,176:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,185:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,194:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,203:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:43,210:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,216:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,226:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,269:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:43,276:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:43,277:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,279:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,283:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,287:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,291:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,293:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,627:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:43,629:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,637:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,642:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,661:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:43,664:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,670:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,678:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,693:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:43,696:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,704:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,709:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,754:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:43,758:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,763:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:43,771:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,000:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:44,002:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,009:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,013:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,024:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:44,027:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,032:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,036:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,044:INFO:Calculating mean and std
2024-11-25 20:00:44,046:INFO:Creating metrics dataframe
2024-11-25 20:00:44,049:INFO:Uploading results into container
2024-11-25 20:00:44,049:INFO:Uploading model into container now
2024-11-25 20:00:44,050:INFO:_master_model_container: 13
2024-11-25 20:00:44,050:INFO:_display_container: 2
2024-11-25 20:00:44,051:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-25 20:00:44,051:INFO:create_model() successfully completed......................................
2024-11-25 20:00:44,166:INFO:SubProcess create_model() end ==================================
2024-11-25 20:00:44,166:INFO:Creating metrics dataframe
2024-11-25 20:00:44,169:INFO:Initializing Dummy Classifier
2024-11-25 20:00:44,170:INFO:Total runtime is 0.13611948092778525 minutes
2024-11-25 20:00:44,170:INFO:SubProcess create_model() called ==================================
2024-11-25 20:00:44,170:INFO:Initializing create_model()
2024-11-25 20:00:44,170:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D0B2EA7D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 20:00:44,170:INFO:Checking exceptions
2024-11-25 20:00:44,171:INFO:Importing libraries
2024-11-25 20:00:44,171:INFO:Copying training dataset
2024-11-25 20:00:44,175:INFO:Defining folds
2024-11-25 20:00:44,175:INFO:Declaring metric variables
2024-11-25 20:00:44,175:INFO:Importing untrained model
2024-11-25 20:00:44,176:INFO:Dummy Classifier Imported successfully
2024-11-25 20:00:44,176:INFO:Starting cross validation
2024-11-25 20:00:44,177:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-25 20:00:44,215:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:44,216:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:44,218:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,218:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,220:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,223:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,223:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,224:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,224:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 20:00:44,225:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 20:00:44,225:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 20:00:44,226:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:44,227:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,227:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,228:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,228:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,235:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,237:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 20:00:44,239:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,261:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:44,261:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:44,262:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:44,262:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,263:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,264:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,266:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,267:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,268:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,268:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 20:00:44,269:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 20:00:44,272:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,273:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,274:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 20:00:44,277:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,280:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:44,283:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,290:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,295:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 20:00:44,299:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,301:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:44,302:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
          ^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krzys\AppData\Roaming\Python\Python311\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-11-25 20:00:44,303:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,304:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,307:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,308:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,309:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 20:00:44,310:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-25 20:00:44,313:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,313:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-11-25 20:00:44,319:INFO:Calculating mean and std
2024-11-25 20:00:44,321:INFO:Creating metrics dataframe
2024-11-25 20:00:44,323:INFO:Uploading results into container
2024-11-25 20:00:44,323:INFO:Uploading model into container now
2024-11-25 20:00:44,325:INFO:_master_model_container: 14
2024-11-25 20:00:44,325:INFO:_display_container: 2
2024-11-25 20:00:44,325:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-11-25 20:00:44,325:INFO:create_model() successfully completed......................................
2024-11-25 20:00:44,440:INFO:SubProcess create_model() end ==================================
2024-11-25 20:00:44,441:INFO:Creating metrics dataframe
2024-11-25 20:00:44,445:WARNING:C:\Users\krzys\.conda\envs\datascience\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-11-25 20:00:44,448:INFO:Initializing create_model()
2024-11-25 20:00:44,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 20:00:44,448:INFO:Checking exceptions
2024-11-25 20:00:44,449:INFO:Importing libraries
2024-11-25 20:00:44,449:INFO:Copying training dataset
2024-11-25 20:00:44,453:INFO:Defining folds
2024-11-25 20:00:44,453:INFO:Declaring metric variables
2024-11-25 20:00:44,454:INFO:Importing untrained model
2024-11-25 20:00:44,454:INFO:Declaring custom model
2024-11-25 20:00:44,455:INFO:Logistic Regression Imported successfully
2024-11-25 20:00:44,456:INFO:Cross validation set to False
2024-11-25 20:00:44,456:INFO:Fitting Model
2024-11-25 20:00:44,489:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-25 20:00:44,489:INFO:create_model() successfully completed......................................
2024-11-25 20:00:44,603:INFO:Initializing create_model()
2024-11-25 20:00:44,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 20:00:44,604:INFO:Checking exceptions
2024-11-25 20:00:44,606:INFO:Importing libraries
2024-11-25 20:00:44,606:INFO:Copying training dataset
2024-11-25 20:00:44,610:INFO:Defining folds
2024-11-25 20:00:44,610:INFO:Declaring metric variables
2024-11-25 20:00:44,611:INFO:Importing untrained model
2024-11-25 20:00:44,611:INFO:Declaring custom model
2024-11-25 20:00:44,611:INFO:K Neighbors Classifier Imported successfully
2024-11-25 20:00:44,613:INFO:Cross validation set to False
2024-11-25 20:00:44,613:INFO:Fitting Model
2024-11-25 20:00:44,625:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-25 20:00:44,625:INFO:create_model() successfully completed......................................
2024-11-25 20:00:44,740:INFO:Initializing create_model()
2024-11-25 20:00:44,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 20:00:44,740:INFO:Checking exceptions
2024-11-25 20:00:44,741:INFO:Importing libraries
2024-11-25 20:00:44,742:INFO:Copying training dataset
2024-11-25 20:00:44,746:INFO:Defining folds
2024-11-25 20:00:44,746:INFO:Declaring metric variables
2024-11-25 20:00:44,746:INFO:Importing untrained model
2024-11-25 20:00:44,746:INFO:Declaring custom model
2024-11-25 20:00:44,747:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-25 20:00:44,748:INFO:Cross validation set to False
2024-11-25 20:00:44,748:INFO:Fitting Model
2024-11-25 20:00:44,759:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-25 20:00:44,759:INFO:create_model() successfully completed......................................
2024-11-25 20:00:44,874:INFO:Initializing create_model()
2024-11-25 20:00:44,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 20:00:44,874:INFO:Checking exceptions
2024-11-25 20:00:44,875:INFO:Importing libraries
2024-11-25 20:00:44,875:INFO:Copying training dataset
2024-11-25 20:00:44,879:INFO:Defining folds
2024-11-25 20:00:44,879:INFO:Declaring metric variables
2024-11-25 20:00:44,879:INFO:Importing untrained model
2024-11-25 20:00:44,879:INFO:Declaring custom model
2024-11-25 20:00:44,881:INFO:Linear Discriminant Analysis Imported successfully
2024-11-25 20:00:44,882:INFO:Cross validation set to False
2024-11-25 20:00:44,882:INFO:Fitting Model
2024-11-25 20:00:44,900:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-25 20:00:44,900:INFO:create_model() successfully completed......................................
2024-11-25 20:00:45,012:INFO:Initializing create_model()
2024-11-25 20:00:45,012:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-25 20:00:45,012:INFO:Checking exceptions
2024-11-25 20:00:45,013:INFO:Importing libraries
2024-11-25 20:00:45,013:INFO:Copying training dataset
2024-11-25 20:00:45,016:INFO:Defining folds
2024-11-25 20:00:45,017:INFO:Declaring metric variables
2024-11-25 20:00:45,017:INFO:Importing untrained model
2024-11-25 20:00:45,017:INFO:Declaring custom model
2024-11-25 20:00:45,019:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-25 20:00:45,021:INFO:Cross validation set to False
2024-11-25 20:00:45,021:INFO:Fitting Model
2024-11-25 20:00:45,195:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-25 20:00:45,195:INFO:create_model() successfully completed......................................
2024-11-25 20:00:45,333:INFO:_master_model_container: 14
2024-11-25 20:00:45,333:INFO:_display_container: 2
2024-11-25 20:00:45,336:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2024-11-25 20:00:45,336:INFO:compare_models() successfully completed......................................
2024-11-25 20:01:13,622:INFO:Initializing predict_model()
2024-11-25 20:01:13,622:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0B323B850>, estimator=KNeighborsClassifier(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D0B29C18A0>)
2024-11-25 20:01:13,622:INFO:Checking exceptions
2024-11-25 20:01:13,622:INFO:Preloading libraries
2024-11-25 20:01:13,623:INFO:Set up data.
2024-11-25 20:01:13,626:INFO:Set up index.
